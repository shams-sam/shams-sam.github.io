<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <!-- (1) Optimize for mobile versions: http://goo.gl/EOpFl -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- (1) force latest IE rendering engine: bit.ly/1c8EiC9 -->
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Regularized Linear Regression | Machine Learning Medium</title>
  <meta name="description" content="Regularization is a process of introducing additional information in order to solve an ill-posed problem or to prevent overfitting" />

  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  
  
  <meta property="og:site_name" content="Machine Learning Medium" />
  <meta property="og:title" content="Regularized Linear Regression"/>
  
  <meta property="og:description" content="Regularization is a process of introducing additional information in order to solve an ill-posed problem or to prevent overfitting" />
  
  <meta property="og:image" content="https://machinelearningmedium.com/assets/images/overfitting.png" />
  <meta property="og:url" content="https://machinelearningmedium.com/2017/09/11/regularized-linear-regression/" >
  <meta property="og:type" content="blog" />
  <meta property="article:published_time" content="2017-09-11T00:00:00+05:30">

  <link rel="canonical" href="https://machinelearningmedium.com/2017/09/11/regularized-linear-regression/"/>
  <link rel="shortcut icon" href="/public/fav.png" type="image/png"/>
  <link rel="stylesheet" href="//brick.a.ssl.fastly.net/Linux+Libertine:400,400i,700,700i/Open+Sans:400,400i,700,700i">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="stylesheet" type="text/css" media="screen" href="/css/main.css" />
  <link rel="stylesheet" type="text/css" media="print" href="/css/print.css" />
  <link rel="stylesheet" type="text/css" href="/css/custom.css" />
  <link rel="stylesheet" type="text/css" href="/public/css/share_bar.css" />
  <link rel="stylesheet" type="text/css" href="/public/css/syntax.css" />
  <link href="https://fonts.googleapis.com/css?family=Fira+Sans:400,600|Open+Sans:400,700" rel="stylesheet">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" >
  <link rel="shortcut icon" href="/public/fav.ico?v1">


  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

</head>

  <body itemscope itemtype="http://schema.org/Article">
    <div class="metabar metabar-header">
  <div class="metabar-inner">
    <div class="quote-div">
      <a class="icon-quote" href="/">
        <i class="fa fa-quote-left fa-pull-left fa-border" aria-hidden="true"></i>
      </a>
    </div>
  </div>
</div>

<div class="sectionbar sectionbar-header">
  <div class="sectionbar-inner">
    <div class="table">
      <div class="category-links table-cell">
        
          <a href=/>Home</a>
        
        
        <a href="/tag/machine-learning">Machine Learning</a>
        
        <a href="/tag/mathematics">Mathematics</a>
        
        <a href="/tag/papers">Papers</a>
        
        <a href="/tag/dsa">DSA</a>
        
        <span class="right-padding-22">|</span>
        <a href=/tags/ class="">Tags</a>
      </div>
      <div class="social-links table-cell">
        <!-- 
          
              <a class="icon-github-alt" href="https://github.com/shams-sam/shams-sam.github.io"  title="Gihub Project" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-github-alt fa-stack-1x"></i>
                </span>
              </a>
          
        
          
              <a class="icon-facebook" href="https://facebook.com/shams-sam"  title="Facebook" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-facebook fa-stack-1x"></i>
                </span>
              </a>
          
        
          
              <a class="icon-twitter" href="https://twitter.com/sshamssam"  title="Twitter" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-twitter fa-stack-1x"></i>
                </span>
              </a>
          
        
          
              <a class="icon-linkedin" href="https://linkedin.com/in/shams-sheikh-20328154"  title="LinkedIn" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-linkedin fa-stack-1x"></i>
                </span>
              </a>
          
        
          
              <a class="icon-envelope" href="mailto:shams.sam@live.com"  title="E-mail" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-envelope fa-stack-1x"></i>
                </span>
              </a>
          
         -->
        <div class="fb-like" data-href="https://www.facebook.com/machinelearningmedium/" data-layout="button" data-action="like" data-size="large" data-show-faces="false" data-share="false"></div>
        <a href="https://twitter.com/sshamssam" class="twitter-follow-button" data-size="large" data-show-screen-name="false" data-dnt="true" data-show-count="false"></a><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
      </div>
    </div>
  </div>
</div>
    <div class="author-strip">
      <div class="author-strip-inner">
        <div class="author-image" style="background-image: url(/assets/images/author.jpg)">Blog Logo</div>
        <div class="author-detail">
          <h4 class="author-name" itemprop="author" itemscope itemtype="http://schema.org/Person"><a href="/about/" style="color: #000000; text-decoration: none;">Shams S</a></h4>
          <h5 class="author-name"> Data Scientist @ Practo </h5>
          <time datetime="2017-09-11T00:00:00+05:30">Sep 11</time>
          <span class="middot">&#183;</span>
          <div class="post-reading">
            <span class="post-reading-time"></span> read
          </div>
        </div>
      </div>
    </div>
    
    <div class="postcover">
    <div class="postimage">
        <div class="postimage-image"  style="background-image: url(/assets/images/overfitting.png) ">
        </div>
    </div>
    
    <figcaption>Image Source: https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/Overfitting.svg/1200px-Overfitting.svg.png</figcaption>
    
    </div>
    <main class="content post-content" role="main">
      <article class="post">
        <div class="noarticleimage">
          <div class="post-meta">
            <h1 class="post-title">Regularized Linear Regression</h1>
            <h2 class="post-description">Regularization is a process of introducing additional information in order to solve an ill-posed problem or to prevent overfitting</h2>
          </div>
        </div>
        <div class="horizontal-divider">&#183; &#183; &#183;</div>
        <section class="post-content">
          <a name="topofpage"></a>
          <p>The intuition of regularization are explained in the previous post: <a href="/2017/09/08/overfitting-and-regularization/" target="_blank">Overfitting and Regularization</a>. The cost function for a regularized linear equation is given by,</p>

<script type="math/tex; mode=display">J(\theta) = {1 \over 2m} \left[ \sum_{i=1}^m \left( h_\theta(x^{(i)}) - y^{(i)} \right)^2 + \lambda \sum_{j=1}^n \theta_j^2 \right] \tag{1}</script>

<ul>
  <li>Where
    <ul>
      <li>\(\lambda \sum_{i=1}^n \theta_j^2\) is the regularization term</li>
      <li>\(\lambda\) is called the <strong>regularization parameter</strong></li>
    </ul>
  </li>
</ul>

<h3 id="regularization-for-gradient-descent">Regularization for Gradient Descent</h3>

<p>Previously, the <strong>gradient descent for linear regression without regularization</strong> was given by,</p>

<script type="math/tex; mode=display">\begin{align}
    \text{repeat until convergence}
    \begin{cases}
      \theta_j := \theta_j - \alpha \left[ {1 \over m} \sum_{i=1}^m \left( h_\theta(x^{(i)}) - y^{(i)} \right) x_j^{(i)} \right]
    \end{cases}
  \end{align}
  \tag{2}</script>

<ul>
  <li>Where \(j \in \{0, 1, \cdots, n\} \)</li>
</ul>

<p>But since the equation for cost function has changed in (1) to include the regularization term, there will be a <strong>change in the derivative of cost function</strong> that was plugged in the gradient descent algorithm,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
    \frac {\partial} {\partial \theta_j} J(\theta) &= \frac {\partial} {\partial \theta_j} \left ({1 \over 2m} \left[ \sum_{i=1}^m \left( h_\theta(x^{(i)}) - y^{(i)} \right)^2 + \lambda \sum_{i=1}^n \theta_j^2 \right] \right) \\
    &= {1 \over m} \sum_{i=1}^m \left( h_\theta(x^{(i)}) - y^{(i)} \right) x_j^{(i)} + \frac {\lambda} {m} \theta_j \\
  \end{align} %]]></script>

<p>Because the first term of cost fuction remains the same, so does the first term of the derivative. So taking <strong>derivative of second term</strong> gives \(\frac {\lambda} {m} \theta_j\) as seen above.</p>

<p>So, (2) can be updated as,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
    \text{repeat until convergence}
    \begin{cases}
      \theta_0 &:= \theta_0 - \alpha \left[ {1 \over m} \sum_{i=1}^m \left( h_\theta(x^{(i)}) - y^{(i)} \right) x_0^{(i)} \right] \\
      \theta_j &:= \theta_j - \alpha \left[ {1 \over m} \sum_{i=1}^m \left( h_\theta(x^{(i)}) - y^{(i)} \right) x_j^{(i)} + \frac {\lambda} {m} \theta_j \right] \\
    \end{cases}
  \end{align} %]]></script>

<ul>
  <li>Where \(j \in \{1, 2, \cdots, n\} \)</li>
</ul>

<p>It can be noticed that, <strong>for case j=0, there is no regularization term</strong> included which is consistent with the convention followed for 
regularization.</p>

<p>The second equation in the gradient descent algorithm above can be written as,</p>

<script type="math/tex; mode=display">\theta_j := \theta_j \left(1 - \alpha {\lambda \over m} \right) - \alpha {1 \over m} \left[ \sum_{i=1}^m \left( h_\theta(x^{(i)}) - y^{(i)} \right) x_j^{(i)}\right]</script>

<ul>
  <li>Where \(\left(1 - \alpha {\lambda \over m} \right) \lt 1\) because \(\alpha\) and \(\lambda\) are both positive.</li>
</ul>

<p>The <strong>implementation</strong> from <a href="/2017/08/23/multivariate-linear-regression/" target="_blank">Mulivariate Linear Regression</a> can be updated with the following <strong>updated regularized functions for cost function, its derivative, and updates</strong>. One, can notice that \(theta_0\) has not been handled seperately in the code. And as expected it <strong>does not affect the regularization</strong> much. It can be implemented in the conventional way by adding a couple of logical expressions to the function</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="s">"""
Regularized Version
"""</span>
<span class="k">def</span> <span class="nf">reg_j_prime_theta</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">order_of_regression</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">data</span> <span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">update_features</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">order_of_regression</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">+=</span> <span class="p">(</span><span class="n">h</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">result</span> <span class="o">+=</span> <span class="n">l</span><span class="o">*</span><span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">result</span>

<span class="k">def</span> <span class="nf">reg_j</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">order_of_regression</span><span class="p">):</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">update_features</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">order_of_regression</span><span class="p">)</span>
        <span class="n">cost</span> <span class="o">+=</span> <span class="n">math</span><span class="o">.</span><span class="nb">pow</span><span class="p">(</span><span class="n">h</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">reg</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">theta</span><span class="p">:</span>
        <span class="n">reg</span> <span class="o">+=</span> <span class="n">math</span><span class="o">.</span><span class="nb">pow</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">reg</span> <span class="o">=</span> <span class="n">reg</span> <span class="o">*</span> <span class="n">l</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">m</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="n">cost</span> <span class="o">+</span> <span class="n">reg</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">reg_update_theta</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">order_of_regression</span><span class="p">):</span>
    <span class="n">temp</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">order_of_regression</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">temp</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">reg_j_prime_theta</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">order_of_regression</span><span class="p">,</span> <span class="n">i</span><span class="p">))</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">theta</span>

<span class="k">def</span> <span class="nf">reg_gradient_descent</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">tolerance</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="p">[],</span> <span class="n">order_of_regression</span> <span class="o">=</span> <span class="mi">2</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">order_of_regression</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="n">prev_j</span> <span class="o">=</span> <span class="mi">10000</span>
    <span class="n">curr_j</span> <span class="o">=</span> <span class="n">reg_j</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">order_of_regression</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">curr_j</span><span class="p">)</span>
    <span class="n">cost_history</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">theta_history</span> <span class="o">=</span> <span class="p">[]</span> 
    <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">curr_j</span> <span class="o">-</span> <span class="n">prev_j</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">tolerance</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">cost_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_j</span><span class="p">)</span>
            <span class="n">theta_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="n">reg_update_theta</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">order_of_regression</span><span class="p">)</span>
            <span class="n">prev_j</span> <span class="o">=</span> <span class="n">curr_j</span>
            <span class="n">curr_j</span> <span class="o">=</span> <span class="n">reg_j</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">order_of_regression</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">counter</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="n">curr_j</span><span class="p">)</span>
            <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Stopped with Error at </span><span class="si">%.5</span><span class="s">f"</span> <span class="o">%</span> <span class="n">prev_j</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">theta</span><span class="p">,</span> <span class="n">cost_history</span><span class="p">,</span> <span class="n">theta_history</span>
<span class="n">reg_theta</span><span class="p">,</span> <span class="n">reg_cost_history</span><span class="p">,</span> <span class="n">reg_theta_history</span> <span class="o">=</span> <span class="n">reg_gradient_descent</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">,</span> <span class="n">order_of_regression</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
</code></pre>
</div>

<p>The following plot is obtained on running a random experiment with <strong>regression of order 150</strong>, which clearly shows how the regularized hypothesis is much better fit to the data.</p>

<p><img src="/assets/2017-09-11-regularized-linear-regression/fig-1-regularized-linear-regression.png?raw=true" alt="Regularizated Linear Regression" /></p>

<h3 id="regularization-for-normal-equation">Regularization for Normal Equation</h3>

<p>The equation and derivation of Normal Equation can be found in the post <a href="/2017/08/28/normal-equation/" target="_blank">Normal Equation</a>. It is given by,</p>

<script type="math/tex; mode=display">\theta = \left( X^TX \right)^{-1}X^Ty</script>

<p>But after adding the regularization term as shown in (1), making very small changes in the derivation in the <a href="/2017/08/28/normal-equation/" target="_blank">post</a>, one can reach the result for regularized normal equation as shown below,</p>

<script type="math/tex; mode=display">\theta = \left( X^TX + \lambda \cdot L\right)^{-1}X^Ty</script>

<ul>
  <li>Where
    <ul>
      <li><strong>I is the identity matrix</strong></li>
      <li>\(L = \begin{bmatrix} 0 &amp; 0 &amp; \cdots &amp;  0 \\ 0 &amp; 1 &amp; \cdots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; \cdots &amp; 1 \\ \end{bmatrix} \) is a <strong>square matrix</strong> of size (n+1)</li>
    </ul>
  </li>
</ul>

<p>If \(m \le n\), then the \(X^TX\) was <strong>non-invertible in the unregularized case</strong> but, \(X^TX + \lambda I\) does not face the same issues and is <strong>always invertible</strong>.</p>

<p>The effect of regularization on regression using normal equation can be seen in the following plot for <strong>regression of order 10</strong>.</p>

<p><img src="/assets/2017-09-11-regularized-linear-regression/fig-2-regularization-for-normal-equation.png?raw=true" alt="Regularizated Linear Regression" /></p>

<blockquote>
  <p>No implementation of regularized normal equation presented as it is very straight forward.</p>
</blockquote>

<h2 id="references">REFERENCES:</h2>

<p><small><a href="https://www.coursera.org/learn/machine-learning/lecture/QrMXd/regularized-linear-regression" target="_blank">Machine Learning: Coursera - Regularized Linear Regression</a></small></p>

        </section>
        <div class="horizontal-divider">· · ·</div>
        <footer class="post-footer">
          <div class="wrap">
            
              <div class="tile">
                <div class="text">
                <a href="/tag/machine-learning" class='category-links'><h1>machine learning</h1></a>
                </div>
              </div>
            
              <div class="tile">
                <div class="text">
                <a href="/tag/andrew-ng" class='category-links'><h1>andrew ng</h1></a>
                </div>
              </div>
            
          </div>
          <section class="share">
            <span id="share-bar">

    <span><i class="fa fa-share-alt"></i></span>

    <span class="share-buttons">
        <span>
        <a  href="https://www.facebook.com/sharer/sharer.php?u=https://machinelearningmedium.com/2017/09/11/regularized-linear-regression/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Facebook" >
            <i class="fa fa-facebook-square"></i>
        </a>
        </span>
        <span>
        <a  href="https://twitter.com/intent/tweet?text=Regularized Linear Regression&url=https://machinelearningmedium.com/2017/09/11/regularized-linear-regression/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Twitter" >
            <i class="fa fa-twitter-square"></i>
        </a>
        </span>
        <span>
        <a  href="https://plus.google.com/share?url=https://machinelearningmedium.com/2017/09/11/regularized-linear-regression/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Google+" >
            <i class="fa fa-google-plus-square"></i>
        </a>
        </span>
        <span>
        <a  href="http://pinterest.com/pin/create/button/?url=https://machinelearningmedium.com/2017/09/11/regularized-linear-regression/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Pinterest" >
            <i class="fa fa-pinterest-square"></i>
        </a>
        </span>
        <span>
        <a  href="http://www.tumblr.com/share/link?url=https://machinelearningmedium.com/2017/09/11/regularized-linear-regression/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Tumblr" >
            <i class="fa fa-tumblr-square"></i>
        </a>
        </span>
        <span>
        <a  href="http://www.reddit.com/submit?url=https://machinelearningmedium.com/2017/09/11/regularized-linear-regression/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Reddit" >
            <i class="fa fa-reddit-square"></i>
        </a>
        </span>
        <span>
        <a  href="https://www.linkedin.com/shareArticle?mini=true&url=https://machinelearningmedium.com/2017/09/11/regularized-linear-regression/&title=Regularized Linear Regression&summary=Regularization is a process of introducing additional information in order to solve an ill-posed problem or to prevent overfitting&source=Machine Learning Medium"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on LinkedIn" >
            <i class="fa fa-linkedin-square"></i>
        </a>
        </span>
        <span>
        <a  href="mailto:?subject=Regularized Linear Regression&amp;body=Check out this site https://machinelearningmedium.com/2017/09/11/regularized-linear-regression/"
            title="Share via Email" >
            <i class="fa fa-envelope-square"></i>
        </a>
        </span>
    </span>

</span>
          </section>
        </footer>
        <!-- <div class="bottom-teaser cf">
          <div class="isLeft">
            <h5 class="index-headline featured"><span>Written by</span></h5>
            <section class="author">
              <div class="author-image" style="background-image: url(/assets/images/author.jpg)">Blog Logo</div>
              <h4>Shams S</h4>
              <p class="bio">Data Scientist @ Practo</p>
              <hr>
              <p class="published">Published on <time datetime="2017-09-11 00:00">11 Sep 2017</time></p>
            </section>
          </div>
          <div class="isRight">
            <h5 class="index-headline featured"><span>Supported by</span></h5>
            <footer class="site-footer">
              <section class="poweredby">Proudly published with <a href="http://jekyllrb.com"> Jekyll</a></section>
              <a class="subscribe" href="/feed.xml"> <span class="tooltip"> <i class="fa fa-rss"></i> You should subscribe to my feed.</span></a>
              <div class="inner">
                <section class="copyright">All content copyright <a href="https://machinelearningmedium.com/">Machine Learning Medium</a> &copy; 2017<br>All rights reserved.</section>
              </div>
            </footer>
          </div>
        </div> -->
        
        <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE */
            var disqus_shortname = 'shams-sam'; /* required: replace example with your forum shortname */

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function() {
                var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        
      </article>
    </main>
    <!-- footer start -->
<div class="footer-container">

<footer class="site-footer">
  <a class="subscribe" href="/feed.xml"> <span class="tooltip"> <i class="fa fa-rss"></i> Subscribe!</span></a>
    <div class="inner">
         <section class="copyright">All content copyright <a href="/">Machine Learning Medium</a> &copy; 2017 &bull; All rights reserved.</section>
         <section class="poweredby">Made with <a href="http://jekyllrb.com"> Jekyll</a></section>
         <section class="poweredby">Inspired by <a href="https://medium.com/"> Medium</a> and <a href="https://github.com/dirkfabisch/mediator">Mediator</a></section>
    </div>
</footer>

<div class="bottom-closer">
  <div class="background-closer-image"  style="background-image: url(/assets/images/footer.jpg)">
    Image
  </div>
  <div class="inner">
    <h1 class="footer-title">Machine Learning Medium</h1>
    <h2 class="footer-description">Mathematics, Machine Learning, Natural Language Processing Etc.</h2>
    <a href=/about/ class="btn">About Me</a>
  </div>
</div>

<!-- footer end -->
</div>

    <script src="https://code.jquery.com/jquery-1.11.1.min.js"></script>
<script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
<script type="text/javascript" src="/assets/js/readingTime.min.js"></script>
<script type="text/javascript" src="/assets/js/index.js"></script>
<script>
(function ($) {
  "use strict";
  $(document).ready(function(){

    var $window = $(window),
    $image = $('.post-image-image, .teaserimage-image');
    
      $window.on('scroll', function() {
        var top = $window.scrollTop();

        if (top < 0 || top > 1500) { return; }
        $image
          .css('transform', 'translate3d(0px, '+top/3+'px, 0px)')
          .css('opacity', 1-Math.max(top/700, 0));
      });
      $window.trigger('scroll');

      var height = $('.article-image').height();
      $('.post-content').css('padding-top', height + 'px');

      $('a[href*=#]:not([href=#])').click(function() {
        if (location.pathname.replace(/^\//,'') == this.pathname.replace(/^\//,'')
         && location.hostname == this.hostname) {
          var target = $(this.hash);
          target = target.length ? target : $('[name=' + this.hash.slice(1) +']');
          if (target.length) {
            $('html,body').animate({ scrollTop: target.offset().top }, 500);
            return false;
          }
        }
      });

  });
}(jQuery));
</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
<script src="/public/js/typed.js"></script>
<script>
  $(function(){
    $(".blog-description").typed({
      strings: ['Mathematics, Machine Learning, Natural Language Processing Etc.'],
      typeSpeed: 50,
      backSpeed: 25,
      loop: true
    });
  });
</script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      },
      CommonHTML: {matchFontHeight: false},
      "HTML-CSS": {matchFontHeight: false},
      SVG: {matchFontHeight: false}
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>



<script>
   (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-108148924-1', 'auto');
ga('send', 'pageview');

</script>


<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = 'https://connect.facebook.net/en_GB/sdk.js#xfbml=1&version=v2.10&appId=391866664565981';
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>
  </body>
</html>
