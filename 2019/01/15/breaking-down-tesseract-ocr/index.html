<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <!-- (1) Optimize for mobile versions: http://goo.gl/EOpFl -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- (1) force latest IE rendering engine: bit.ly/1c8EiC9 -->
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  

  <title>Breaking down Tesseract OCR | Machine Learning Medium</title>
  <meta name="description" content="Tesseract, an open source OCR project was originally developed by HP between 1984 and 1994 as a part of PhD research project at HP Labs, Bristol." />

  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  
  
  <meta property="og:site_name" content="Machine Learning Medium" />
  <meta property="og:title" content="Breaking down Tesseract OCR"/>
  
  <meta property="og:description" content="Tesseract, an open source OCR project was originally developed by HP between 1984 and 1994 as a part of PhD research project at HP Labs, Bristol." />
  
  <meta property="og:image" content="https://machinelearningmedium.com/assets/images/tesseract.jpg" />
  <meta property="og:url" content="https://machinelearningmedium.com/2019/01/15/breaking-down-tesseract-ocr/" >
  <meta property="og:type" content="blog" />
  <meta property="article:published_time" content="2019-01-15T00:00:00+00:00">

  <link rel="canonical" href="https://machinelearningmedium.com/2019/01/15/breaking-down-tesseract-ocr/"/>
  <link rel="shortcut icon" href="/public/fav.png" type="image/png"/>
  <link rel="stylesheet" href="//brick.a.ssl.fastly.net/Linux+Libertine:400,400i,700,700i/Open+Sans:400,400i,700,700i">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="stylesheet" type="text/css" media="screen" href="/css/main.css" />
  <link rel="stylesheet" type="text/css" media="print" href="/css/print.css" />
  <link rel="stylesheet" type="text/css" href="/css/custom.css" />
  <link rel="stylesheet" type="text/css" href="/public/css/share_bar.css" />
  <link rel="stylesheet" type="text/css" href="/public/css/syntax.css" />
  <link href="https://fonts.googleapis.com/css?family=Fira+Sans:400,600|Open+Sans:400,700" rel="stylesheet">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" >
  <link rel="shortcut icon" href="/public/fav.ico?v1">


  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

</head>

  <body itemscope itemtype="http://schema.org/Article">
    <div class="metabar metabar-header">
  <div class="metabar-inner">
    <div class="quote-div">
      <a class="icon-quote" href="/">
        <i class="fa fa-quote-left fa-pull-left fa-border" aria-hidden="true"></i>
      </a>
    </div>
  </div>
</div>

<div class="sectionbar sectionbar-header">
  <div class="sectionbar-inner">
    <div class="table">
      <div class="category-links table-cell">
        
          <a href=/>Home</a>
        
        
        <a href="/tag/machine-learning">Machine Learning</a>
        
        <a href="/tag/mathematics">Mathematics</a>
        
        <a href="/tag/papers">Papers</a>
        
        <span class="right-padding-22">|</span>
        <a href=/collections/ class="">Collections</a>
        <a href=/tags/ class="">Tags</a>
        
          <span class="right-padding-22">|</span>
          <a class="icon-search" href="/search/"><i class="fa fa-search"></i></a>
        
      </div>
      <div class="social-links table-cell">
        <!-- 
          
              <a class="icon-github-alt" href="https://github.com/shams-sam/shams-sam.github.io"  title="Gihub Project" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-github-alt fa-stack-1x"></i>
                </span>
              </a>
          
        
          
              <a class="icon-facebook" href="https://facebook.com/shams-sam"  title="Facebook" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-facebook fa-stack-1x"></i>
                </span>
              </a>
          
        
          
              <a class="icon-twitter" href="https://twitter.com/sshamssam"  title="Twitter" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-twitter fa-stack-1x"></i>
                </span>
              </a>
          
        
          
              <a class="icon-linkedin" href="https://linkedin.com/in/shams-sheikh-20328154"  title="LinkedIn" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-linkedin fa-stack-1x"></i>
                </span>
              </a>
          
        
          
              <a class="icon-envelope" href="mailto:shams.sam@live.com"  title="E-mail" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-envelope fa-stack-1x"></i>
                </span>
              </a>
          
         -->
        <div class="fb-like" data-href="https://www.facebook.com/machinelearningmedium/" data-layout="button" data-action="like" data-size="large" data-show-faces="false" data-share="false"></div>
        <a href="https://twitter.com/sshamssam" class="twitter-follow-button" data-size="large" data-show-screen-name="false" data-dnt="true" data-show-count="false"></a><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
      </div>
    </div>
  </div>
</div>
    <div class="author-strip">
      <div class="author-strip-inner">
        <div class="author-image" style="background-image: url(/assets/images/author.jpg)">Blog Logo</div>
        <div class="author-detail">
          <h4 class="author-name" itemprop="author" itemscope itemtype="http://schema.org/Person"><a href="/about/" style="color: #000000; text-decoration: none;">Shams S</a></h4>
          <h5 class="author-name"> Research Assistant @ Purdue University </h5>
          <time datetime="2019-01-15T00:00:00+00:00">Jan 15</time>
          <span class="middot">&#183;</span>
          <div class="post-reading">
            <span class="post-reading-time"></span> read
          </div>
        </div>
      </div>
    </div>
    
    <div class="postcover">
    <div class="postimage">
        <div class="postimage-image"  style="background-image: url(/assets/images/tesseract.jpg) ">
        </div>
    </div>
    
    <figcaption>Image Source: http://s3.amazonaws.com/libapps/accounts/57039/images/Tesseract.jpg</figcaption>
    
    </div>
    <main class="content post-content" role="main">
      <article class="post">
        <div class="noarticleimage">
          <div class="post-meta">
            <h1 class="post-title">Breaking down Tesseract OCR</h1>
            <section class="share">
            <span id="share-bar">

    <span><i class="fa fa-share-alt"></i></span>

    <span class="share-buttons">
        <span>
        <a  href="https://www.facebook.com/sharer/sharer.php?u=https://machinelearningmedium.com/2019/01/15/breaking-down-tesseract-ocr/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Facebook" >
            <i class="fa fa-facebook-square"></i>
        </a>
        </span>
        <span>
        <a  href="https://twitter.com/intent/tweet?text=Breaking down Tesseract OCR&url=https://machinelearningmedium.com/2019/01/15/breaking-down-tesseract-ocr/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Twitter" >
            <i class="fa fa-twitter-square"></i>
        </a>
        </span>
        <span>
        <a  href="https://plus.google.com/share?url=https://machinelearningmedium.com/2019/01/15/breaking-down-tesseract-ocr/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Google+" >
            <i class="fa fa-google-plus-square"></i>
        </a>
        </span>
        <span>
        <a  href="http://pinterest.com/pin/create/button/?url=https://machinelearningmedium.com/2019/01/15/breaking-down-tesseract-ocr/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Pinterest" >
            <i class="fa fa-pinterest-square"></i>
        </a>
        </span>
        <span>
        <a  href="http://www.tumblr.com/share/link?url=https://machinelearningmedium.com/2019/01/15/breaking-down-tesseract-ocr/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Tumblr" >
            <i class="fa fa-tumblr-square"></i>
        </a>
        </span>
        <span>
        <a  href="http://www.reddit.com/submit?url=https://machinelearningmedium.com/2019/01/15/breaking-down-tesseract-ocr/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Reddit" >
            <i class="fa fa-reddit-square"></i>
        </a>
        </span>
        <span>
        <a  href="https://www.linkedin.com/shareArticle?mini=true&url=https://machinelearningmedium.com/2019/01/15/breaking-down-tesseract-ocr/&title=Breaking down Tesseract OCR&summary=Tesseract, an open source OCR project was originally developed by HP between 1984 and 1994 as a part of PhD research project at HP Labs, Bristol.&source=Machine Learning Medium"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on LinkedIn" >
            <i class="fa fa-linkedin-square"></i>
        </a>
        </span>
        <span>
        <a  href="mailto:?subject=Breaking down Tesseract OCR&amp;body=Check out this site https://machinelearningmedium.com/2019/01/15/breaking-down-tesseract-ocr/"
            title="Share via Email" >
            <i class="fa fa-envelope-square"></i>
        </a>
        </span>
    </span>

</span>
          </section>
            <h2 class="post-description">Tesseract, an open source OCR project was originally developed by HP between 1984 and 1994 as a part of PhD research project at HP Labs, Bristol.</h2>
          </div>
        </div>
        <div class="horizontal-divider">&#183; &#183; &#183;</div>
        <section class="post-content">
          <a name="topofpage"></a>
          <h3 id="introduction">Introduction</h3>

<ul>
  <li>It was originally an HP research project between 1984 and 1994, which was presented at 1995 UNLV Annual Test of OCR Accuracy where it performed beyond expectations.</li>
  <li>Purpose of tesseract was integration with the flatbed HP scanners with objectives such as compression which was not possible with the then existing commercial OCR solutions which were struggling with accuracy.</li>
  <li>During a phase of development, work concentrated on improving rejection efficiency than on base-level accuracy.</li>
  <li>Finally in 2005, Tesseract was released as an open-source project by HP available at Google Code until it was finally moved to <a href="https://github.com/tesseract-ocr/tesseract" target="\_blank">Github</a> for open-source contribution.</li>
</ul>

<h3 id="architecture">Architecture</h3>

<ul>
  <li>
    <p>Because of HP’s proprietary layout analysis technology, Tesseract did not have it’s own dedicated layout analyser. As a result, Tesseract assumes the inputs to be <strong>binary image with optional polygonal text regions defined</strong>.</p>
  </li>
  <li>
    <p><strong>Connected Component Analysis</strong> is the first step in which the outlines of the components are stored. Outlines are gathered together, purely by nesting, into <strong>Blobs</strong>.</p>
  </li>
  <li>
    <p>Blobs are organized into text lines, and the the lines and regions are analyzed for <strong>fixed pitch</strong> or <strong>proportional text</strong>. The lines are broken into words differently based on the kind of character spacing. Fixed pitch text is chopped immidiately by character cells. Proportional text is broken into words using <strong>definite spaces or fuzzy spaces</strong>.</p>
  </li>
  <li>
    <p><strong>Recognition</strong> proceeds as a <strong>two-pass process</strong>. During the <strong>first pass</strong>, attempt is made to recognize each word. The words that are satifactorily identified are passed to an <strong>adaptive classifier</strong> as training data. As a result the adaptive classifier gets a chance at improving results among text lower down on the page. In order to utilize the training of adaptive classifier on the text near the top of the page as <strong>second pass</strong> is performed, during which words that were not recognized well enough are classified again.</p>
  </li>
  <li>
    <p><strong>Final Phase</strong> resolves the <strong>fuzzy spaces</strong>, and checks <strong>alternative hypotheses</strong> for the x-height to locate small-cap text.</p>
  </li>
</ul>

<h3 id="line-and-word-finding">Line and Word Finding</h3>

<p><strong>1. Line Finding</strong></p>

<ul>
  <li>
    <p>Algorithm is designed so that skewed page can be recognized without having to deskew, thus preventing any loss of image quality.</p>
  </li>
  <li>
    <p><strong>Blob filtering</strong> and <strong>line construction</strong> are key parts of this process.</p>
  </li>
  <li>
    <p>Under the assumption that most blobs have uniform text size, a simple <strong>percentile height filter</strong> removes drop-caps and vertically touching characters and <strong>median height</strong> approximates the text size in the region.</p>
  </li>
  <li>
    <p>Blobs smaller than a certain fraction of the median height are filtered out, being most likely punctuation, diacritical marks and noise.</p>
  </li>
  <li>
    <p>The filtered blobs are more likely to fit a model of <strong>non-overlapping, parallel, but sloping lines</strong>. Sorting and processing the blobs by x-coordinates makes it possible to assign blobs to a unique text line, while tracking the slope across the page.</p>
  </li>
  <li>
    <p>Once the lines are assigned, a <strong>least median of squares fit</strong> is used to estimate the baselines, and filtered-out blobs are fitted back into appropriate lines.</p>
  </li>
  <li>
    <p>Final step merges blobs that overlap by at least half horizontally, putting diacritical marks together with the correct base and correctly associating parts of some broken characters.</p>
  </li>
</ul>

<p><strong>2. Baseline Fitting</strong></p>

<ul>
  <li>Using the text lines, baselines are fitted precisely using a <strong>quadratic spline</strong>, which allows Tesseract to handle pages with curved baselines.</li>
</ul>

<p><img src="/assets/2019-01-15-breaking-down-tesseract-ocr/fig-1-curved-fitted-baseline.png?raw=true" alt="Fig-1: Curved Fitted Baseline" /></p>

<ul>
  <li>Baseline fitting is done by partitioning the blobs into groups of reasonable continuous displacement for the original straight baseline. A quadratic spline is fitted to the most populous partition by a least square fit.</li>
</ul>

<p><strong>3. Fixed Pitch Detection and Chopping</strong></p>

<ul>
  <li>Lines are tested to determine whether they are fixed pitch. Where it finds fixed pitch text, Tesseract chops the words into characters using pitch, and disables the <strong>chopper</strong> and <strong>associator</strong> on these words for the <strong>word recognition step</strong>.</li>
</ul>

<p><img src="/assets/2019-01-15-breaking-down-tesseract-ocr/fig-2-fixed-pitch-chopped-word.png?raw=true" alt="Fig-2: Fixed Pitch Chopped Word" /></p>

<p><strong>4. Proportional Word Finding</strong></p>

<ul>
  <li>Detecting word boundaries in a not-fixed-pitch or proportional text spacing is highly non-trivial task.</li>
</ul>

<p><img src="/assets/2019-01-15-breaking-down-tesseract-ocr/fig-3-difficult-word-spacing.png?raw=true" alt="Fig-3: Difficult Word Spacing" /></p>

<ul>
  <li>
    <p>For example, the gap between the tens and units of ‘11.9%’ is similar size to general space, but is certainly larger the kerned space between ‘erated’ and ‘junk’. Another case can be noticed that there is no horizontal gap between the bounding box of ‘of’ and ‘financial’.</p>
  </li>
  <li>
    <p>Tesseract solves most of these problems by measuring <strong>gaps in a limited vertical range between baseline and mean line</strong>. Spaces close to a threshold are made <strong>fuzzy</strong>, where the decisions are made after <strong>word recognition</strong>.</p>
  </li>
</ul>

<h3 id="word-recognition">Word Recognition</h3>

<ul>
  <li>
    <p>A major part of any word recognition algorithm is to identify how a word should be segmented into characters.</p>
  </li>
  <li>
    <p>The initial segmented outputs from line finding is classified first. The non-fixed pitch text in the remaining text is classified using other word recognition steps.</p>
  </li>
</ul>

<p><strong>1. Chopping Joined Characters</strong></p>

<ul>
  <li>
    <p>Tesseract attempts to improve the result by chopping the blob with worst confidence from the character classifier.</p>
  </li>
  <li>
    <p><strong>Chop points</strong> are found from concave vertices of a poligonal approximation of the outline, which may have a concave vertex opposite or a line segment. It may take upto 3 pairs of chop points to successfully separate joined characters from ASCII set.</p>
  </li>
</ul>

<p><img src="/assets/2019-01-15-breaking-down-tesseract-ocr/fig-4-candidate-chop-points-and-chop.png?raw=true" alt="Fig-4: Candidate Chop Points and Chop" /></p>

<ul>
  <li>Chops are executed in priority order. Any chop that fails to improve the confidence of the result is undone, but not completely discarded so that it can be re-used by the <strong>associator</strong> if needed.</li>
</ul>

<p><strong>2. Associating Broken Characters</strong></p>

<ul>
  <li>
    <p>After the potential chops have been exhausted, if the word is still not good enough, it is given to the <strong>associator</strong>, which makes a <strong>best first search</strong> of the segmentation graph of the possible combinations of the maximally chopped blobs into candidate characters.</p>
  </li>
  <li>
    <p>The search pulls candidate new states from a priority queue and evaluates them by classifying unclassified combinations of fragments.</p>
  </li>
  <li>
    <p>The chop-then-associate method is inefficient but it gives a benefit of simpler data structures that would be required to maintain the full segmentation graph.</p>
  </li>
</ul>

<p><img src="/assets/2019-01-15-breaking-down-tesseract-ocr/fig-5-broken-characters.png?raw=true" alt="Fig-5: Broken Characters recognized by Tesseract" /></p>

<ul>
  <li>This ability of Tesseract to successfully classify broken characters gave it an edge over the contemporaries.</li>
</ul>

<h3 id="static-character-classifier">Static Character Classifier</h3>

<p><strong>1. Features</strong></p>

<ul>
  <li>
    <p>Early version of Tesseract used <strong>topological features</strong>, which are independent of font and size but are not robust to issues found in real-life images.</p>
  </li>
  <li>
    <p>Another idea for classification involved use of segments of the polygonal approximation as features, but this method is also not robust to damaged characters.</p>
  </li>
</ul>

<p><img src="/assets/2019-01-15-breaking-down-tesseract-ocr/fig-6-poligonal-approximation-features.png?raw=true" alt="Fig-6: Differences in Polygonal Approximation for same character" /></p>

<ul>
  <li>
    <p>Solution to these problems lie in the fact that the features in the unknown need not be the same as the features in the training data. During training, <strong>segments of a polygonal approximation</strong> are used for features, but during recognition, features of a small, fixed length are extracted from the outline and matched many-to-one against the clustered prototype features of the training data.</p>
  </li>
  <li>
    <p><strong>The process of small features matching large prototypes is easily able to cope with recognition of damaged words.</strong> It’s main problem is that the computational cost of computing the distance between an unknown and a prototype is very high.</p>
  </li>
</ul>

<p><strong>2. Classfication</strong></p>

<ul>
  <li>
    <p>This stage proceeds as a <strong>two-step process</strong>. First step involves a <strong>class pruner</strong> that creates a shortlist of character classes that the unknown might match.</p>
  </li>
  <li>
    <p>The classes shortlisted in step one are taken further to the next step, where the actual similarity is calculated from the feature bit vectors. <strong>Each prototype character class is represented by a logical sum-of-product expression with each term called a configuration</strong>.</p>
  </li>
</ul>

<p><strong>3. Training Data</strong></p>

<p>The classifier is trained on a mere 20 samples of 94 characters from 8 fonts in a single size, but with 4 attributes (normal, bold, italic, bold italic), making the total of 60160 training samples.</p>

<h3 id="linguistic-analysis">Linguistic Analysis</h3>

<ul>
  <li>
    <p>Whenver the word recognition module is considering a new segmentation, the linguistic model (called <strong>permuter</strong>) choses the best available word string in the categories: <strong>Top frequent word, Top dictionary word, Top numeric word, Top UPPER case word, Top lower case word (with optional initial upper)</strong>, where the final decision for segmentation is simply the word with the lowest total distance rating.</p>
  </li>
  <li>
    <p>Since words from different segmentations may have different number of characters in them, it would be hard to compare these words directly (even if a classifier claims to produce probabilities, which Tesseract does not).</p>
  </li>
  <li>
    <p>Tesseract instead produces two numbers to solve this issue, namely,</p>
    <ul>
      <li><strong>Confidence</strong>, is minus the normalized distance from the prototype. It is confidence in the sense that greater the number better a metric it is.</li>
      <li><strong>Rating</strong> is product of normalized distance from the prototype and total outline length in the unknown character.</li>
    </ul>
  </li>
</ul>

<h3 id="adaptive-classifier">Adaptive Classifier</h3>

<ul>
  <li>
    <p>OCR engines are benefitted from use of an adaptive classifier because the static classifier has to be good at generalizing to any kind of font, its ability to discriminate between different characters or between characters and non-characters is weakened.</p>
  </li>
  <li>
    <p>Tesseract has a font-sensitive adaptive classifier that is trained using the output of the static classifiers which is commonly used to obtain greater discrimination within each document, where the number of fonts is limited.</p>
  </li>
  <li>
    <p>It uses the same features and classifier as the static classifier to train the adaptive classifier. <strong>The only significant difference between the two classifiers apart from the training data is that the adaptive classifier uses the isotropic baseline/x-height normalization, whereas the static classifier normalizes the characters by the centroid (first moment) for position, and second moments for anisotropic size normalization.</strong></p>
  </li>
  <li>
    <p>The baseline normalization helps distinguish the upper and lower case characters and also improves immunity to noise specks.</p>
  </li>
</ul>

<p><img src="/assets/2019-01-15-breaking-down-tesseract-ocr/fig-7-baseline-and-moment-normalized.png?raw=true" alt="Fig-7: Baseline and Moment Normalized letters" /></p>

<ul>
  <li>The main benefit of character moment normalization is <strong>removal of font aspect ratio</strong> and some degree of <strong>font stroke width</strong>. It also makes recognition of subscripts and superscripts easier, but requires an additional feature to distinguish the uppercase and lowercase characters.</li>
</ul>

<h1 id="references">REFERENCES</h1>

<p><small><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/33418.pdf" target="\_blank">An Overview of the Tesseract OCR Engine</a></small></p>

        </section>
        <footer class="post-footer">
          <div class="wrap">
            
              <div class="tile">
                <div class="text">
                <a href="/tag/vision" class='category-links'><h1>vision</h1></a>
                </div>
              </div>
            
              <div class="tile">
                <div class="text">
                <a href="/tag/ocr" class='category-links'><h1>ocr</h1></a>
                </div>
              </div>
            
              <div class="tile">
                <div class="text">
                <a href="/tag/machine-learning" class='category-links'><h1>machine-learning</h1></a>
                </div>
              </div>
            
              <div class="tile">
                <div class="text">
                <a href="/tag/papers" class='category-links'><h1>papers</h1></a>
                </div>
              </div>
            
          </div>
        </footer>
        <div class="horizontal-divider">· · ·</div>
        <!-- <div class="bottom-teaser cf">
          <div class="isLeft">
            <h5 class="index-headline featured"><span>Written by</span></h5>
            <section class="author">
              <div class="author-image" style="background-image: url(/assets/images/author.jpg)">Blog Logo</div>
              <h4>Shams S</h4>
              <p class="bio">Research Assistant @ Purdue University</p>
              <hr>
              <p class="published">Published on <time datetime="2019-01-15 00:00">15 Jan 2019</time></p>
            </section>
          </div>
          <div class="isRight">
            <h5 class="index-headline featured"><span>Supported by</span></h5>
            <footer class="site-footer">
              <section class="poweredby">Proudly published with <a href="http://jekyllrb.com"> Jekyll</a></section>
              <a class="subscribe" href="/feed.xml"> <span class="tooltip"> <i class="fa fa-rss"></i> You should subscribe to my feed.</span></a>
              <div class="inner">
                <section class="copyright">All content copyright <a href="https://machinelearningmedium.com/">Machine Learning Medium</a> &copy; 2019<br>All rights reserved.</section>
              </div>
            </footer>
          </div>
        </div> -->
        <br>
        
        <div id="vc-feelback-main" data-access-token="334e9d2a5dc341469cda15d8c4bd935e" data-display-type="4"></div>
        
        <nav class="page-navigation" role="navigation">
  
    <a href=/2018/10/09/algorithmic-fairness/ class="arrow-button left-arrow-button"><span class="left-arrow"></span><span class="label left-label">Social Bias in Machine Learning</span></a>
  
  
    <a href=/2019/06/02/social-learning-networks/ class="arrow-button right-arrow-button"><span class="label right-label">Social Learning Networks</span><span class="right-arrow"></span></a>
  
</nav>
        
        <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE */
            var disqus_shortname = 'shams-sam'; /* required: replace example with your forum shortname */

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function() {
                var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        
      </article>
    </main>
    <!-- footer start -->
<div class="footer-container">

<footer class="site-footer">
  <a class="subscribe" href="/feed.xml"> <span class="tooltip"> <i class="fa fa-rss"></i> Subscribe!</span></a>
    <div class="inner">
         <section class="copyright">All content copyright <a href="/">Machine Learning Medium</a> &copy; 2019 &bull; All rights reserved.</section>
         <section class="poweredby">Made with <a href="http://jekyllrb.com"> Jekyll</a></section>
         <section class="poweredby">Inspired by <a href="https://medium.com/"> Medium</a> and <a href="https://github.com/dirkfabisch/mediator">Mediator</a></section>
    </div>
</footer>

<div class="bottom-closer">
  <div class="background-closer-image"  style="background-image: url(/assets/images/footer.jpg)">
    Image
  </div>
  <div class="inner">
    <h1 class="footer-title">Machine Learning Medium</h1>
    <h2 class="footer-description">Recursing the Rabbit Hole</h2>
    <a href=/about/ class="btn">About Me</a>
  </div>
</div>

<!-- footer end -->
</div>

    <script src="https://code.jquery.com/jquery-1.11.1.min.js"></script>
<script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
<script type="text/javascript" src="/assets/js/readingTime.min.js"></script>
<script type="text/javascript" src="/assets/js/index.js"></script>
<script>
(function ($) {
  "use strict";
  $(document).ready(function(){

    var $window = $(window),
    $image = $('.post-image-image, .teaserimage-image');
    
      $window.on('scroll', function() {
        var top = $window.scrollTop();

        if (top < 0 || top > 1500) { return; }
        $image
          .css('transform', 'translate3d(0px, '+top/3+'px, 0px)')
          .css('opacity', 1-Math.max(top/700, 0));
      });
      $window.trigger('scroll');

      var height = $('.article-image').height();
      $('.post-content').css('padding-top', height + 'px');

      $('a[href*=#]:not([href=#])').click(function() {
        if (location.pathname.replace(/^\//,'') == this.pathname.replace(/^\//,'')
         && location.hostname == this.hostname) {
          var target = $(this.hash);
          target = target.length ? target : $('[name=' + this.hash.slice(1) +']');
          if (target.length) {
            $('html,body').animate({ scrollTop: target.offset().top }, 500);
            return false;
          }
        }
      });

  });
}(jQuery));
</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
<script src="/public/js/typed.js"></script>
<script>
  $(function(){
    $(".blog-description").typed({
      strings: ['Recursing the Rabbit Hole'],
      typeSpeed: 50,
      backSpeed: 25,
      loop: true
    });
  });
</script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      },
      CommonHTML: {matchFontHeight: false},
      "HTML-CSS": {matchFontHeight: false},
      SVG: {matchFontHeight: false}
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>



<script>
   (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-108148924-1', 'auto');
ga('send', 'pageview');

</script>


<div id="fb-root"></div>

<script>
  (function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = 'https://connect.facebook.net/en_GB/sdk.js#xfbml=1&version=v2.10&appId=391866664565981';
    fjs.parentNode.insertBefore(js, fjs);
  }(document, 'script', 'facebook-jssdk'));
</script>


<script> 
(function() { 
  var v = document.createElement('script'); v.async = true; 
  v.src = "https://assets-prod.vicomi.com/vicomi.js?token=334e9d2a5dc341469cda15d8c4bd935e"; 
  var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(v, s); 
})(); 
</script>

  </body>
</html>
