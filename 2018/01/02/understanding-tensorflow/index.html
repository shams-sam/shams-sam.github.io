<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <!-- (1) Optimize for mobile versions: http://goo.gl/EOpFl -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- (1) force latest IE rendering engine: bit.ly/1c8EiC9 -->
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  

  <title>Understanding TensorFlow | Machine Learning Medium</title>
  <meta name="description" content="TensorFlow is an open source, data flow graph based, numerical computation library. Nodes in the graph represent mathematical operations, while edges represent the multidimensional data arrays communicated between them." />

  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  
  
  <meta property="og:site_name" content="Machine Learning Medium" />
  <meta property="og:title" content="Understanding TensorFlow"/>
  
  <meta property="og:description" content="TensorFlow is an open source, data flow graph based, numerical computation library. Nodes in the graph represent mathematical operations, while edges represent the multidimensional data arrays communicated between them." />
  
  <meta property="og:image" content="https://machinelearningmedium.com/assets/images/convolution.jpg" />
  <meta property="og:url" content="https://machinelearningmedium.com/2018/01/02/understanding-tensorflow/" >
  <meta property="og:type" content="blog" />
  <meta property="article:published_time" content="2018-01-02T00:00:00+05:30">

  <link rel="canonical" href="https://machinelearningmedium.com/2018/01/02/understanding-tensorflow/"/>
  <link rel="shortcut icon" href="/public/fav.png" type="image/png"/>
  <link rel="stylesheet" href="//brick.a.ssl.fastly.net/Linux+Libertine:400,400i,700,700i/Open+Sans:400,400i,700,700i">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="stylesheet" type="text/css" media="screen" href="/css/main.css" />
  <link rel="stylesheet" type="text/css" media="print" href="/css/print.css" />
  <link rel="stylesheet" type="text/css" href="/css/custom.css" />
  <link rel="stylesheet" type="text/css" href="/public/css/share_bar.css" />
  <link rel="stylesheet" type="text/css" href="/public/css/syntax.css" />
  <link href="https://fonts.googleapis.com/css?family=Fira+Sans:400,600|Open+Sans:400,700" rel="stylesheet">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" >
  <link rel="shortcut icon" href="/public/fav.ico?v1">


  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

</head>

  <body itemscope itemtype="http://schema.org/Article">
    <div class="metabar metabar-header">
  <div class="metabar-inner">
    <div class="quote-div">
      <a class="icon-quote" href="/">
        <i class="fa fa-quote-left fa-pull-left fa-border" aria-hidden="true"></i>
      </a>
    </div>
  </div>
</div>

<div class="sectionbar sectionbar-header">
  <div class="sectionbar-inner">
    <div class="table">
      <div class="category-links table-cell">
        
          <a href=/>Home</a>
        
        
        <a href="/tag/machine-learning">Machine Learning</a>
        
        <a href="/tag/mathematics">Mathematics</a>
        
        <a href="/tag/papers">Papers</a>
        
        <span class="right-padding-22">|</span>
        <a href=/collections/ class="">Collections</a>
        <a href=/tags/ class="">Tags</a>
        
          <span class="right-padding-22">|</span>
          <a class="icon-search" href="/search/"><i class="fa fa-search"></i></a>
        
      </div>
      <div class="social-links table-cell">
        <!-- 
          
              <a class="icon-github-alt" href="https://github.com/shams-sam/shams-sam.github.io"  title="Gihub Project" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-github-alt fa-stack-1x"></i>
                </span>
              </a>
          
        
          
              <a class="icon-facebook" href="https://facebook.com/shams-sam"  title="Facebook" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-facebook fa-stack-1x"></i>
                </span>
              </a>
          
        
          
              <a class="icon-twitter" href="https://twitter.com/sshamssam"  title="Twitter" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-twitter fa-stack-1x"></i>
                </span>
              </a>
          
        
          
              <a class="icon-linkedin" href="https://linkedin.com/in/shams-sheikh-20328154"  title="LinkedIn" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-linkedin fa-stack-1x"></i>
                </span>
              </a>
          
        
          
              <a class="icon-envelope" href="mailto:shams.sam@live.com"  title="E-mail" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-envelope fa-stack-1x"></i>
                </span>
              </a>
          
         -->
        <div class="fb-like" data-href="https://www.facebook.com/machinelearningmedium/" data-layout="button" data-action="like" data-size="large" data-show-faces="false" data-share="false"></div>
        <a href="https://twitter.com/sshamssam" class="twitter-follow-button" data-size="large" data-show-screen-name="false" data-dnt="true" data-show-count="false"></a><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
      </div>
    </div>
  </div>
</div>
    <div class="author-strip">
      <div class="author-strip-inner">
        <div class="author-image" style="background-image: url(/assets/images/author.jpg)">Blog Logo</div>
        <div class="author-detail">
          <h4 class="author-name" itemprop="author" itemscope itemtype="http://schema.org/Person"><a href="/about/" style="color: #000000; text-decoration: none;">Shams S</a></h4>
          <h5 class="author-name"> Data Scientist @ Practo </h5>
          <time datetime="2018-01-02T00:00:00+05:30">Jan 2</time>
          <span class="middot">&#183;</span>
          <div class="post-reading">
            <span class="post-reading-time"></span> read
          </div>
        </div>
      </div>
    </div>
    
    <div class="postcover">
    <div class="postimage">
        <div class="postimage-image"  style="background-image: url(/assets/images/convolution.jpg) ">
        </div>
    </div>
    
    <figcaption>Image Source: https://d17h27t6h515a5.cloudfront.net/topher/2016/October/580f8f75_8-convolutional-neural-networks/8-convolutional-neural-networks.jpg</figcaption>
    
    </div>
    <main class="content post-content" role="main">
      <article class="post">
        <div class="noarticleimage">
          <div class="post-meta">
            <h1 class="post-title">Understanding TensorFlow</h1>
            <section class="share">
            <span id="share-bar">

    <span><i class="fa fa-share-alt"></i></span>

    <span class="share-buttons">
        <span>
        <a  href="https://www.facebook.com/sharer/sharer.php?u=https://machinelearningmedium.com/2018/01/02/understanding-tensorflow/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Facebook" >
            <i class="fa fa-facebook-square"></i>
        </a>
        </span>
        <span>
        <a  href="https://twitter.com/intent/tweet?text=Understanding TensorFlow&url=https://machinelearningmedium.com/2018/01/02/understanding-tensorflow/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Twitter" >
            <i class="fa fa-twitter-square"></i>
        </a>
        </span>
        <span>
        <a  href="https://plus.google.com/share?url=https://machinelearningmedium.com/2018/01/02/understanding-tensorflow/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Google+" >
            <i class="fa fa-google-plus-square"></i>
        </a>
        </span>
        <span>
        <a  href="http://pinterest.com/pin/create/button/?url=https://machinelearningmedium.com/2018/01/02/understanding-tensorflow/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Pinterest" >
            <i class="fa fa-pinterest-square"></i>
        </a>
        </span>
        <span>
        <a  href="http://www.tumblr.com/share/link?url=https://machinelearningmedium.com/2018/01/02/understanding-tensorflow/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Tumblr" >
            <i class="fa fa-tumblr-square"></i>
        </a>
        </span>
        <span>
        <a  href="http://www.reddit.com/submit?url=https://machinelearningmedium.com/2018/01/02/understanding-tensorflow/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Reddit" >
            <i class="fa fa-reddit-square"></i>
        </a>
        </span>
        <span>
        <a  href="https://www.linkedin.com/shareArticle?mini=true&url=https://machinelearningmedium.com/2018/01/02/understanding-tensorflow/&title=Understanding TensorFlow&summary=TensorFlow is an open source, data flow graph based, numerical computation library. Nodes in the graph represent mathematical operations, while edges represent the multidimensional data arrays communicated between them.&source=Machine Learning Medium"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on LinkedIn" >
            <i class="fa fa-linkedin-square"></i>
        </a>
        </span>
        <span>
        <a  href="mailto:?subject=Understanding TensorFlow&amp;body=Check out this site https://machinelearningmedium.com/2018/01/02/understanding-tensorflow/"
            title="Share via Email" >
            <i class="fa fa-envelope-square"></i>
        </a>
        </span>
    </span>

</span>
          </section>
            <h2 class="post-description">TensorFlow is an open source, data flow graph based, numerical computation library. Nodes in the graph represent mathematical operations, while edges represent the multidimensional data arrays communicated between them.</h2>
          </div>
        </div>
        <div class="horizontal-divider">&#183; &#183; &#183;</div>
        <section class="post-content">
          <a name="topofpage"></a>
          <h3 id="prerequisites">Prerequisites</h3>

<ul>
  <li>Python Programming</li>
  <li>Basics of Arrays</li>
  <li>Basics of Machine Learning</li>
</ul>

<h3 id="tensforflow-apis">TensforFlow APIs</h3>

<ul>
  <li>The lowest level TensorFlow API, <strong>TensorFlow Core</strong>, provides the complete programming control, recommended for machine learning researchers who require fine levels of control over their model.</li>
  <li>The higher level TensorFlow APIs are built on top of TensorFlow Core. These APIs are easier to learn and use. Higher level APIs also provide convinient wrappers for repetitive tasks, e.g. <strong>tf.estimator</strong> helps to manage datasets, estimators, training, inference etc.</li>
</ul>

<h3 id="terminologies">Terminologies</h3>

<ul>
  <li><strong>Computational Graph</strong> defines the series of TensorFlow operations arranged in the form of graph nodes.</li>
  <li><strong>Dataset</strong>: Similar to placeholders, but Dataset represents a potentially large set of elements that can be accessed using iterators. These are the preferred method of streaming data into a model.</li>
  <li><strong>Node</strong> in a TensorFlow graph takes zero or more tensors as inputs and produces a tensor as an output, e.g. <strong>Constant</strong> is a type of node in TensorFlow that takes no inputs and outputs the value that it stores internally (as defined in the defination of Tensorflow nodes earlier).</li>
  <li><strong>Operations</strong> are another kind of node in TensorFlow used to build the computational graphs, that consume and produce tensors.</li>
  <li><strong>Placeholder</strong> is a promise to provide value later. These serve the purpose or parameters or arguments to a graph which represents a dynamic function based on inputs.</li>
  <li><strong>Rank:</strong> The number of dimensions of a tensor (similar to rank of a matrix).</li>
  <li><strong>Session</strong>, used for evaluation of TensorFlow graphs, encapsulates the control and state of the TensorFlow runtime.</li>
  <li><strong>Shape:</strong> Often confused with rank, shape refers to the tuple of integers specifying the length of tensor along each dimension.</li>
  <li><strong>Tensor:</strong> A set of primitive types shaped into an array of any number of dimensions. It can be considered a higher-dimensional vector. Tensorflow <strong>used numpy arrays</strong> to represent tensor values.</li>
  <li><strong>TensorBoard</strong> is a TensorFlow utility used to visualize the computational graphs.</li>
</ul>

<h3 id="tensorflow-imports">TensorFlow Imports</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
</code></pre></div></div>

<ul>
  <li>
    <p><strong>absolute_import</strong>: The distinction between absolute and relative imports can be considered to be analogous to the concept of absolute or relative file paths or even URLs, i.e. absolute imports specify the exact path of the imports while the relative imports work w.r.t. the working directory. Therefore for the code that is to be shared among peers, it is recommended to use absolute imports.</p>
  </li>
  <li>
    <p><strong>division</strong>: The import belongs to era when the debate on <strong>true division vs floor division</strong> was on in the python community i.e. for python 2.*. The import in python 3.* is not required as the regular division operator itself is the true division while the floor division is denoted by \\.</p>
  </li>
  <li>
    <p><strong>print_function</strong>: This import is again not necessary in python 3.*. It is used to invalidate the print as a statement in python 2.*. Post call to this function, print only has valid represetnation as a function, which has some apparent advantages over the print as a statement, e.g. print function can be used inside lambda function or list and dictionary comprehensions.</p>
  </li>
</ul>

<p>Generally all the <strong>__future__ imports</strong> are recommended to be kept at the top of the file because it changes the way the compiler behaves and the set of rules it follows.</p>

<h3 id="initialization">Initialization</h3>

<p>Basically, a TensorFlow Core program can be split into two sections:</p>

<ul>
  <li><strong>Building</strong> the computational graph</li>
  <li><strong>Running</strong> the computational graph</li>
</ul>

<p>Tensor initialization is done as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">3.0</span><span class="p">,</span> 
                <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> 
                <span class="n">name</span><span class="o">=</span><span class="s">'a'</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">4.0</span><span class="p">,</span> 
                <span class="n">name</span><span class="o">=</span><span class="s">'b'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</code></pre></div></div>

<p>The output shows that the <strong>default type of a tensor is float32</strong>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Tensor</span><span class="p">(</span><span class="s">"a:0"</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
<span class="n">Tensor</span><span class="p">(</span><span class="s">"b:0"</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</code></pre></div></div>

<p>Also, the print statement does not print value assigned to the nodes. The actual values will be displayed only on evaluation of the nodes. In TensorFlow the evaluation of a node can only be done within a session as shown below.</p>

<h3 id="session">Session</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">])</span>
</code></pre></div></div>

<p>More complex TensorFlow graphs are built using operation nodes. For example,</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">total</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">total</span><span class="p">)</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">total</span><span class="p">)</span>
</code></pre></div></div>

<p>Mutliple tensors can be passed to a <code class="highlighter-rouge">tf.Session.run</code>, i.e., the <code class="highlighter-rouge">run</code> method handles any combination of tuples dictionaries,</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">({</span><span class="s">'ab'</span><span class="p">:</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="s">'total'</span><span class="p">:</span> <span class="n">total</span><span class="p">})</span>
</code></pre></div></div>

<blockquote>
  <p>Some tensorflow functions return <code class="highlighter-rouge">tf.Operations</code> instead of <code class="highlighter-rouge">tf.Tensors</code>. Also, the result of calling run on an Operation is <code class="highlighter-rouge">None</code> because Operations are run to cause a side-effect and not to retrieve a value.</p>
</blockquote>

<p>During a call to <code class="highlighter-rouge">tf.Session.run</code>, and <code class="highlighter-rouge">tf.Tensor</code> holds a single value throughout that run. This is consistent with the notion that state of graph is saved in a session making sure once initialized a tensor will not have updated values unless operated upon.</p>

<h3 id="tensorboard">TensorBoard</h3>

<p>In order to visualize the TensorFlow graph, following command can be followed:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="s">'/path/to/save/'</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
</code></pre></div></div>

<p>or</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="s">'/path/to/save'</span><span class="p">)</span>
<span class="n">writer</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">())</span>
</code></pre></div></div>

<p>Now run the following command on the terminal, ensure <strong>TensorBoard</strong> is installed.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensorboard <span class="nt">--logdir</span><span class="o">=</span>/path/to/save
</code></pre></div></div>

<p><img src="/assets/2018-01-02-understanding-tensorflow/fig-1-tensorflow-graph-visualization.png?raw=true" alt="Fig.1 TensorFlow Graph Visualization" /></p>

<p>It leads to the above graph displayed, which is an apt representation of the minimal graph that has been built so far. But it is a constant graph as the input nodes are constants. In order to build a parameterized graph, placeholders are used as shown below.</p>

<h3 id="feeding-data-using-placeholders">Feeding Data using Placeholders</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'a'</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'b'</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">a</span><span class="o">+</span><span class="n">b</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="p">{</span><span class="n">a</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="mi">4</span><span class="p">}))</span>
<span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">a</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">b</span><span class="p">:</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]}))</span>

<span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="s">'/path/to/save'</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
</code></pre></div></div>
<p><img src="/assets/2018-01-02-understanding-tensorflow/fig-2-placeholder-graph.png?raw=true" alt="Fig.2 TensorFlow Placeholder Graph" /></p>

<blockquote>
  <p>The <code class="highlighter-rouge">feed_dict</code> argument can be used to overwrite any tensor in the graph.</p>
</blockquote>

<p>The only <strong>difference between placeholders and other <code class="highlighter-rouge">tf.Tensors</code></strong> is that placeholders throw and error if no value is fed to them.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">run</span><span class="p">(</span>
    <span class="n">fetches</span><span class="p">,</span>
    <span class="n">feed_dict</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">run_metadata</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</code></pre></div></div>

<p>Runs operations and <strong>evaluates tensors listed in fetches</strong> argument. The method will run <strong>one step of TensorFlow computation</strong>, by running necessary graph consisting of tensors and operations to <strong>evaluate the dependencies of Tensors listed in fetches</strong>, substituting the values listed in the feed_dict for the corresponding values.</p>

<p>The fetches argument can be a <strong>single graph element, nested list, tuple, namedtuple, dict, or OrderedDict</strong> that consists of graph elements as its leaves.</p>

<p>The graph element may belong to one of the following classes:</p>

<ul>
  <li>tf.Operation: fetched value is None.</li>
  <li>tf.Tensor: fetched value is a numpy ndarray containing the value of the tensor.</li>
  <li>tf.SparseTensor: fetched value is a tf.SparseTensorValue.</li>
  <li>get_tensor_handle op: fetched value is a numpy ndarray containing the handle of the tensor.</li>
  <li>string: name of a tensor or operation in the graph.</li>
</ul>

<blockquote>
  <p>The value returned by <code class="highlighter-rouge">run()</code> has the same shape as the fetches argument, where leaves are replaced by corresponding values returned by TensorFlow.</p>
</blockquote>

<p>Example code:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">collections</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span><span class="s">'data'</span><span class="p">,</span> <span class="p">[</span><span class="s">'a'</span><span class="p">,</span> <span class="s">'b'</span><span class="p">])</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">({</span><span class="s">'k1'</span><span class="p">:</span> <span class="n">data</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="s">'k2'</span><span class="p">:</span> <span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">a</span><span class="p">]})</span>
<span class="k">print</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
</code></pre></div></div>

<p>It can be observed on executing the code that the output of run saved has the same structure as the input to the fetches argument, i.e. a dictionary of namedtuple of lists and list of lists.</p>

<p>The keys in feed_dict can belong to one of the following:</p>

<ul>
  <li>If key is <code class="highlighter-rouge">tf.Tensor</code>: value maybe a scalar, string, list, or numpy array.</li>
  <li>If key is <code class="highlighter-rouge">tf.Placeholder</code>: shape of the value will be checked with shape of the placeholder for compatibility.</li>
  <li>If key is <code class="highlighter-rouge">tf.SparseTensor</code>: value should be <code class="highlighter-rouge">tf.SparseTensorValue</code>.</li>
  <li>If key is nested tuple of Tensors or SparseTensors, then the value should be follow the same nested structure that maps to corresponding values in the key’s structure.</li>
</ul>

<blockquote>
  <p>Each value in the feed_dict must be convertible to a numpy array of the dtype of corresponding key.</p>
</blockquote>

<p>The following errors are raised by run function:</p>

<ul>
  <li><code class="highlighter-rouge">RuntimeError</code>: If the Session is in invalid state or closed.</li>
  <li><code class="highlighter-rouge">TypeError</code>: If fetches or feed_dict keys are of inappropriate types.</li>
  <li><code class="highlighter-rouge">ValueError</code>: If fetches or feed_dict keys are invalid or refer to a tensor that does not exist.</li>
</ul>

<h3 id="importing-data">Importing Data</h3>

<p><code class="highlighter-rouge">tf.data</code> api helps to build complex input pipelines. It basically helps deal with large amounts of data, maybe belonging to different formats and apply complicated transformations to the data such as image augmentation or handling text sequences of different lengths for preprocessing and batch processing use cases. The pipelines help abstract processes and also modularize the code for easier debugging and managing of the code.</p>

<p>Some of the abstractions dataset introduces in TensorFlow are summarized below:</p>

<ul>
  <li><code class="highlighter-rouge">tf.data.Dataset</code> is used to represent a sequence of elements where each element contains one or more Tensor objects.</li>
</ul>

<p>Creating a source (<code class="highlighter-rouge">Dataset.from_tensor_slices()</code>) contructs a dataset from one or more <code class="highlighter-rouge">tf.Tensor</code> objects, while applying a transformation (<code class="highlighter-rouge">Dataset.batch()</code>) contructs a dataset from one or more <code class="highlighter-rouge">tf.data.Dataset</code> objects.</p>

<ul>
  <li><code class="highlighter-rouge">tf.data.Iterator</code> is used to extract elements from a dataset, and acts as an interface between the input pipeline and the models.</li>
</ul>

<p>The <code class="highlighter-rouge">get_next</code> method of iterator is called for streaming the data.</p>

<p>Simplest iterator is made using <code class="highlighter-rouge">make_one_shot_iterator</code> method as shown below. It is associated with a particular dataset and iterates through it once.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,],</span>
    <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,],</span>
    <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,],</span>
    <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,],</span>
<span class="p">]</span>
<span class="n">slices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">next_item</span> <span class="o">=</span> <span class="n">slices</span><span class="o">.</span><span class="n">make_one_shot_iterator</span><span class="p">()</span><span class="o">.</span><span class="n">get_next</span><span class="p">()</span>
<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">next_item</span><span class="p">))</span>
  <span class="k">except</span> <span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">OutOfRangeError</span><span class="p">:</span>
    <span class="k">break</span>
</code></pre></div></div>

<p>Reaching the end of dataset, if <code class="highlighter-rouge">get_next</code> is called, <code class="highlighter-rouge">OutOfRangeError</code> is thrown by the Dataset.</p>

<p>For more sophisticated uses, <code class="highlighter-rouge">Iterator.initializer</code> is used that helps reinitialize and parameterize an iterator with different datasets, including running over a single or a set of datasets multiple number of times in the same program.</p>

<blockquote>
  <p>Placeholders work for simple experiments, but Datasets are the preferred method of streaming data into a model.</p>
</blockquote>

<p>A dataset consists of <strong>elements</strong> that each have exactly the same structure, i.e. an element contains one or more <code class="highlighter-rouge">tf.Tensor</code> objects, called <strong>components</strong>. A component has <code class="highlighter-rouge">tf.DType</code> representing the type of elements in the tensor, and a <code class="highlighter-rouge">tf.TensorShape</code> (maybe partially specified, for example batch size might be missing but dimension of elements in batch may be present) representing the static shape of each element.</p>

<p>Similarly the  <code class="highlighter-rouge">Dataset.output_types</code> and <code class="highlighter-rouge">Dataset.output_shapes</code> inspect the inferred types and shapes of each component of the dataset element.</p>

<p>It is optional but often helps to <strong>name the components</strong> in a dataset element. To summarize, one can use tuples, <code class="highlighter-rouge">collections.namedtuples</code> or a dictionary mapping strings to tensors to represent a single element in a <code class="highlighter-rouge">Dataset</code>.</p>

<p>Sample code to see the above properties:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">print_dtype</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">print_string</span><span class="o">=</span><span class="s">""</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span> <span class="o">==</span> <span class="nb">tuple</span><span class="p">:</span>
        <span class="n">print_string</span> <span class="o">+=</span> <span class="s">"("</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">input_data</span><span class="p">:</span>
            <span class="n">print_string</span> <span class="o">=</span> <span class="n">print_tuple</span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">print_string</span><span class="p">)</span>
        <span class="n">print_string</span> <span class="o">+=</span> <span class="s">")"</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">print_string</span> <span class="o">+=</span> <span class="nb">str</span><span class="p">(</span><span class="n">input_data</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">+</span> <span class="s">", "</span>
    <span class="k">return</span> <span class="n">print_string</span>

<span class="k">def</span> <span class="nf">print_dimension</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">print_string</span><span class="o">=</span><span class="s">""</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span> <span class="o">==</span> <span class="nb">tuple</span><span class="p">:</span>
        <span class="n">print_string</span> <span class="o">+=</span> <span class="s">"("</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">input_data</span><span class="p">:</span>
            <span class="n">print_string</span> <span class="o">=</span> <span class="n">print_dimension</span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">print_string</span><span class="p">)</span>
        <span class="n">print_string</span> <span class="o">+=</span> <span class="s">")"</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">print_string</span> <span class="o">+=</span> <span class="nb">str</span><span class="p">(</span><span class="n">input_data</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">+</span> <span class="s">", "</span>
    <span class="k">return</span> <span class="n">print_string</span>

<span class="n">dataset1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">]))</span>
<span class="n">element1</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">make_initializable_iterator</span><span class="p">()</span><span class="o">.</span><span class="n">get_next</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"dataset1:"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\t</span><span class="s">"</span><span class="p">,</span> <span class="n">print_dtype</span><span class="p">(</span><span class="n">element1</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\t</span><span class="s">"</span><span class="p">,</span> <span class="n">print_dimension</span><span class="p">(</span><span class="n">element1</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\t</span><span class="s">"</span><span class="p">,</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">output_types</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\t</span><span class="s">"</span><span class="p">,</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">output_shapes</span><span class="p">)</span>

<span class="n">dataset2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span>
   <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="mi">4</span><span class="p">]),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="n">maxval</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)))</span>
<span class="n">element2</span> <span class="o">=</span> <span class="n">dataset2</span><span class="o">.</span><span class="n">make_initializable_iterator</span><span class="p">()</span><span class="o">.</span><span class="n">get_next</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"dataset2:"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\t</span><span class="s">"</span><span class="p">,</span> <span class="n">print_dtype</span><span class="p">(</span><span class="n">element2</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\t</span><span class="s">"</span><span class="p">,</span> <span class="n">print_dimension</span><span class="p">(</span><span class="n">element2</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\t</span><span class="s">"</span><span class="p">,</span> <span class="n">dataset2</span><span class="o">.</span><span class="n">output_types</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\t</span><span class="s">"</span><span class="p">,</span> <span class="n">dataset2</span><span class="o">.</span><span class="n">output_shapes</span><span class="p">)</span>

<span class="n">dataset3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="nb">zip</span><span class="p">((</span><span class="n">dataset1</span><span class="p">,</span> <span class="n">dataset2</span><span class="p">))</span>
<span class="n">element3</span> <span class="o">=</span> <span class="n">dataset3</span><span class="o">.</span><span class="n">make_initializable_iterator</span><span class="p">()</span><span class="o">.</span><span class="n">get_next</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"dataset3:"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\t</span><span class="s">"</span><span class="p">,</span> <span class="n">print_dtype</span><span class="p">(</span><span class="n">element3</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\t</span><span class="s">"</span><span class="p">,</span> <span class="n">print_dimension</span><span class="p">(</span><span class="n">element3</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\t</span><span class="s">"</span><span class="p">,</span> <span class="n">dataset3</span><span class="o">.</span><span class="n">output_types</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\t</span><span class="s">"</span><span class="p">,</span> <span class="n">dataset3</span><span class="o">.</span><span class="n">output_shapes</span><span class="p">)</span>
</code></pre></div></div>

<p>Outputs:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataset1</span><span class="p">:</span>
    <span class="o">&lt;</span><span class="n">dtype</span><span class="p">:</span> <span class="s">'float32'</span><span class="o">&gt;</span><span class="p">,</span> 
    <span class="p">(</span><span class="mi">10</span><span class="p">,),</span> 
    <span class="o">&lt;</span><span class="n">dtype</span><span class="p">:</span> <span class="s">'float32'</span><span class="o">&gt;</span>
    <span class="p">(</span><span class="mi">10</span><span class="p">,)</span>
<span class="n">dataset2</span><span class="p">:</span>
    <span class="p">(</span><span class="n">second</span><span class="p">:</span><span class="o">&lt;</span><span class="n">dtype</span><span class="p">:</span> <span class="s">'int32'</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">first</span><span class="p">:</span><span class="o">&lt;</span><span class="n">dtype</span><span class="p">:</span> <span class="s">'float32'</span><span class="o">&gt;</span><span class="p">,</span> <span class="p">)</span>
    <span class="p">(</span><span class="n">second</span><span class="p">:(</span><span class="mi">100</span><span class="p">,),</span> <span class="n">first</span><span class="p">:(),</span> <span class="p">)</span>
    <span class="p">{</span><span class="s">'second'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="s">'first'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">}</span>
    <span class="p">{</span><span class="s">'second'</span><span class="p">:</span> <span class="n">TensorShape</span><span class="p">([</span><span class="n">Dimension</span><span class="p">(</span><span class="mi">100</span><span class="p">)]),</span> <span class="s">'first'</span><span class="p">:</span> <span class="n">TensorShape</span><span class="p">([])}</span>
<span class="n">dataset3</span><span class="p">:</span>
    <span class="p">(</span><span class="n">d1</span><span class="p">:</span><span class="o">&lt;</span><span class="n">dtype</span><span class="p">:</span> <span class="s">'float32'</span><span class="o">&gt;</span><span class="p">,</span> <span class="p">(</span><span class="n">second</span><span class="p">:</span><span class="o">&lt;</span><span class="n">dtype</span><span class="p">:</span> <span class="s">'int32'</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">first</span><span class="p">:</span><span class="o">&lt;</span><span class="n">dtype</span><span class="p">:</span> <span class="s">'float32'</span><span class="o">&gt;</span><span class="p">,</span> <span class="p">))</span>
    <span class="p">(</span><span class="n">d1</span><span class="p">:(</span><span class="mi">10</span><span class="p">,),</span> <span class="p">(</span><span class="n">second</span><span class="p">:(</span><span class="mi">100</span><span class="p">,),</span> <span class="n">first</span><span class="p">:(),</span> <span class="p">))</span>
    <span class="p">{</span><span class="s">'d1'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="s">'d2'</span><span class="p">:</span> <span class="p">{</span><span class="s">'second'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="s">'first'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">}}</span>
    <span class="p">{</span><span class="s">'d1'</span><span class="p">:</span> <span class="n">TensorShape</span><span class="p">([</span><span class="n">Dimension</span><span class="p">(</span><span class="mi">10</span><span class="p">)]),</span> <span class="s">'d2'</span><span class="p">:</span> <span class="p">{</span><span class="s">'second'</span><span class="p">:</span> <span class="n">TensorShape</span><span class="p">([</span><span class="n">Dimension</span><span class="p">(</span><span class="mi">100</span><span class="p">)]),</span> <span class="s">'first'</span><span class="p">:</span> <span class="n">TensorShape</span><span class="p">([])}}</span>
</code></pre></div></div>

<p>So, the <strong>basic mechanics</strong> of import data can be listed as follows:</p>

<ul>
  <li>
    <p><strong>Define a source</strong> is the first step in defining an input pipeline. For example, data can be imported from in-memory tensors using <code class="highlighter-rouge">tf.data.Dataset.from_tensors()</code> or <code class="highlighter-rouge">tf.data.Dataset.from_tensor_slices()</code>. It can also be imported from disk if the data is in <strong>recommended TFRecord</strong> format using <code class="highlighter-rouge">tf.data.TFRecordDataset</code></p>
  </li>
  <li>
    <p><strong>Transformations</strong> can be applied on any dataset to obtain subsequent dataset objects. This can be achieved by chaining preprocessing or transformation operations. For example, <strong>per-element transformations</strong> can be applied using <code class="highlighter-rouge">Dataset.map()</code> or <strong>multi-element transformations</strong> can be applied using <code class="highlighter-rouge">Dataset.batch()</code>.</p>
  </li>
</ul>

<p>Dataset transformations support datasets of any structure. The element structure determines the argument of a function. For example,</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataset1</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">...</span><span class="p">)</span>

<span class="n">dataset2</span> <span class="o">=</span> <span class="n">dataset2</span><span class="o">.</span><span class="n">flat_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="o">...</span><span class="p">)</span>

<span class="n">dataset3</span> <span class="o">=</span> <span class="n">dataset3</span><span class="o">.</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span> <span class="o">...</span><span class="p">)</span>
</code></pre></div></div>

<p>From the example above it can be seen that the <strong>lambda function can take any structure as the input</strong> based on the structure of an element in the dataset, however complex it is.</p>

<ul>
  <li>
    <p><strong>Define an iterator</strong> to stream data into the model. The iterator can be <strong>one-shot iterator</strong> as in the example above or one of the types listed below.</p>

    <ul>
      <li>
        <p><strong>One-shot iterator</strong> is the simplest iterator that supports iterating only once through the dataset and does not require an explicit initialization. Hence, as a by-product, it does not allow parameterization.</p>
      </li>
      <li>
        <p><strong>Initializable iterator</strong> requires an explicit <code class="highlighter-rouge">iterator.initializer</code> operation before using it. At the cost of this inconvinience, it gives the flexibility to parameterize the defination of dataset using placeholders.</p>
      </li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">max_value</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[])</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="nb">range</span><span class="p">(</span><span class="n">max_value</span><span class="p">)</span>
<span class="n">iterator</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">make_initializable_iterator</span><span class="p">()</span>
<span class="n">next_element</span> <span class="o">=</span> <span class="n">iterator</span><span class="o">.</span><span class="n">get_next</span><span class="p">()</span>

<span class="c"># parameter passing for the placeholder</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">iterator</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">max_value</span><span class="p">:</span> <span class="mi">10</span><span class="p">})</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
  <span class="n">value</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">next_element</span><span class="p">)</span>
  <span class="k">assert</span> <span class="n">i</span> <span class="o">==</span> <span class="n">value</span>
</code></pre></div></div>

<ul>
  <li><strong>Reinitializable iterator</strong> can be initialized from multiple different dataset objects. Basically, while the datasets may change they have the same structure attributed to each element of the dataset. A reinitializable iterator is defined by its structure and any dataset complying to that structure can used to initialize the iterator.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># two different datasets with same structure</span>
<span class="n">training_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="nb">map</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([],</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>

<span class="c"># define the iterator using the structure property</span>
<span class="n">iterator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Iterator</span><span class="o">.</span><span class="n">from_structure</span><span class="p">(</span><span class="n">training_dataset</span><span class="o">.</span><span class="n">output_types</span><span class="p">,</span>
                                           <span class="n">training_dataset</span><span class="o">.</span><span class="n">output_shapes</span><span class="p">)</span>
<span class="n">next_element</span> <span class="o">=</span> <span class="n">iterator</span><span class="o">.</span><span class="n">get_next</span><span class="p">()</span>

<span class="n">training_init</span> <span class="o">=</span> <span class="n">iterator</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="n">training_dataset</span><span class="p">)</span>
<span class="n">validation_init</span> <span class="o">=</span> <span class="n">iterator</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span>

<span class="c"># initialize for training set</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">training_init</span><span class="p">)</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">next_element</span><span class="p">)</span>

<span class="c"># reinitialize for validation set</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_init</span><span class="p">)</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">next_element</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li><strong>Feedable iterator</strong> is used along with <code class="highlighter-rouge">tf.placeholder</code> to select <code class="highlighter-rouge">Iterator</code> to use in each call of <code class="highlighter-rouge">tf.Session.run</code>, via the <code class="highlighter-rouge">feed_dict</code> mechanism. It does not require one to initialize the iterator from the start of a dataset when switching between the iterators. The <code class="highlighter-rouge">tf.data.Iterator.from_string_handle</code> can be used to define a feedable iterator.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">string_handle</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[])</span>
<span class="n">iterator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Iterator</span><span class="o">.</span><span class="n">from_string_handle</span><span class="p">(</span>
    <span class="n">string_handle</span><span class="p">,</span> 
    <span class="n">training_dataset</span><span class="o">.</span><span class="n">output_types</span><span class="p">,</span> 
    <span class="n">training_dataset</span><span class="o">.</span><span class="n">output_shapes</span>
<span class="p">)</span>
<span class="n">next_element</span> <span class="o">=</span> <span class="n">iterator</span><span class="o">.</span><span class="n">get_next</span><span class="p">()</span>

<span class="c"># get string handles of each iterator</span>
<span class="n">training_handle</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">training_iterator</span><span class="o">.</span><span class="n">string_handle</span><span class="p">())</span>
<span class="n">validation_handle</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_iterator</span><span class="o">.</span><span class="n">string_handle</span><span class="p">())</span>

<span class="c"># using training iterator</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">next_element</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">string_handle</span><span class="p">:</span> <span class="n">training_handle</span><span class="p">})</span>

<span class="c"># using validation iterator</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">next_element</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">string_handle</span><span class="p">:</span> <span class="n">validation_handle</span><span class="p">})</span>
</code></pre></div></div>

<h3 id="layers">Layers</h3>

<p>A trainable model is implemented in TensorFlow by means of using Layers which adds trainable parameters to a graph. A layer packages the variables and the operations that act on them. For example, <strong>densely-connected layer</strong> performs weighted sum across all inputs from each output and applies an <strong>optional activation function</strong>. The connection weights and biases are managed by the layer object.</p>

<p>In order to apply layer to an input, the layer is called as a function with input as an argument.</p>

<p>After calling the layer as a function, based on the inputs to the layer it sets up shape of weight matrices compatible with the input. Now, the layers contain variables that must be initialized before they can be used.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">'x'</span><span class="p">)</span>
<span class="n">linear_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'dense_layer'</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">linear_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]]})</span>
</code></pre></div></div>

<blockquote>
  <p>Calling <code class="highlighter-rouge">tf.global_variables_initializer</code> only creates and returns a handle to tensorflow operation which will initialize all global variables on call of <code class="highlighter-rouge">tf.Session.run</code>.</p>
</blockquote>

<p><strong>For each layer class (like <code class="highlighter-rouge">tf.layers.Dense</code>) there exists a shortcut function in TensorFlow (like <code class="highlighter-rouge">tf.layers.dense</code>) that creates and runs the layer in a single call.</strong> But this approach allows no access for the <code class="highlighter-rouge">tf.layers.Layer</code> object which might cause difficulties in debugging and introspection or layer reuse possibilities.</p>

<p>The graph of a linear model looks as shown below.</p>

<p><img src="/assets/2018-01-02-understanding-tensorflow/fig-3-linear-model.png?raw=true" alt="Fig.3 Linear Model Visualization" /></p>

<p>where the linear_model block internally has the structure as shown in Fig. 4 which abides by \eqref{1}.</p>

<p><img src="/assets/2018-01-02-understanding-tensorflow/fig-4-dense-layer.png?raw=true" alt="Fig.4 Linear Model Visualization" /></p>

<script type="math/tex; mode=display">y = Wx + b \tag{1} \label{1}</script>

<p>where W is the weights being fed by the kernel, x is the input vector being fed by the input placeholder and b is the bias.</p>

<blockquote>
  <p>Feature columns can be experimented with using <code class="highlighter-rouge">tf.feature_column.input_layer</code> function for dense columns as input and <code class="highlighter-rouge">tf.feature_column.indicator_column</code> for categorical indicators as input.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">features</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'sales'</span> <span class="p">:</span> <span class="p">[[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">]],</span>
    <span class="s">'department'</span><span class="p">:</span> <span class="p">[</span><span class="s">'sports'</span><span class="p">,</span> <span class="s">'sports'</span><span class="p">,</span> <span class="s">'gardening'</span><span class="p">,</span> <span class="s">'gardening'</span><span class="p">]}</span>

<span class="n">department_column</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">feature_column</span><span class="o">.</span><span class="n">categorical_column_with_vocabulary_list</span><span class="p">(</span>
        <span class="s">'department'</span><span class="p">,</span> <span class="p">[</span><span class="s">'sports'</span><span class="p">,</span> <span class="s">'gardening'</span><span class="p">])</span>
<span class="n">department_column</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">feature_column</span><span class="o">.</span><span class="n">indicator_column</span><span class="p">(</span><span class="n">department_column</span><span class="p">)</span>

<span class="n">columns</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">feature_column</span><span class="o">.</span><span class="n">numeric_column</span><span class="p">(</span><span class="s">'sales'</span><span class="p">),</span>
    <span class="n">department_column</span>
<span class="p">]</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">feature_column</span><span class="o">.</span><span class="n">input_layer</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">columns</span><span class="p">)</span>

<span class="n">var_init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
<span class="n">table_init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tables_initializer</span><span class="p">()</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">((</span><span class="n">var_init</span><span class="p">,</span> <span class="n">table_init</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>
</code></pre></div></div>

<p><strong>Feature columns can have internal state</strong>, like layers and so need to be initialized. Similarly, categorical columns use lookup tables internally and hence require <code class="highlighter-rouge">tf.table_initializer</code> additionally.</p>

<blockquote>
  <p>Categorical input fed using indicator vectors are one-hot encoded.</p>
</blockquote>

<h3 id="training">Training</h3>

<ul>
  <li>Define the data and labels.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>Define the model</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>At this point, model output can be evaluated</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># initialize session and variable</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>

<span class="c"># extract model output</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
</code></pre></div></div>

<p>The output would not be correct as the model is not trained to optimize model parameters for accuracy.</p>

<ul>
  <li>To optimize the model, a loss has to be defined.</li>
</ul>

<p>Using mean squared error,</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span> 
    <span class="n">predictions</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>

<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>After defining a loss, one of the optimizers provided by TensorFlow out of box can be used as optimization algorithm.</li>
</ul>

<p>The optimizers are defined in <code class="highlighter-rouge">tf.train.Optimizer</code>. Using the simplest <strong>gradient descent</strong> implemented in <code class="highlighter-rouge">tf.train.GradientDescentOptimizer</code>,</p>

<blockquote>
  <p>Gradient Descent modifies each variable according to the magnitude of the derivative of loss with respect to that variable.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>Training the model</li>
</ul>

<p>At this stage the model graph is built and the only task pending is to <strong>call the evaluate train iteratively to minimize loss by optimizing model trainable parameters</strong> by updating the corresponding variables.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">loss_value</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">((</span><span class="n">train</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>
</code></pre></div></div>

<ul>
  <li>Evaluate model predictions</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predictions</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>Model Graph</li>
</ul>

<p>The model graph generated from the above training example can be seen below.</p>

<p><img src="/assets/2018-01-02-understanding-tensorflow/fig-5-example-model.png?raw=true" alt="Fig.5 Example Model Graph" /></p>

<p>Since the model inputs are constants, it can be seen that <strong>the dense layer in the graph has no input</strong> being fed from outside, rather is a part of the dense block.</p>

<h2 id="references">REFERENCES:</h2>

<p><small><a href="https://www.tensorflow.org/programmers_guide/low_level_intro" target="_blank">TensorFlow Low-level Introduction</a></small></p>

        </section>
        <footer class="post-footer">
          <div class="wrap">
            
              <div class="tile">
                <div class="text">
                <a href="/tag/machine-learning" class='category-links'><h1>machine-learning</h1></a>
                </div>
              </div>
            
              <div class="tile">
                <div class="text">
                <a href="/tag/tensorflow" class='category-links'><h1>tensorflow</h1></a>
                </div>
              </div>
            
              <div class="tile">
                <div class="text">
                <a href="/tag/library" class='category-links'><h1>library</h1></a>
                </div>
              </div>
            
          </div>
        </footer>
        <div class="horizontal-divider">· · ·</div>
        <!-- <div class="bottom-teaser cf">
          <div class="isLeft">
            <h5 class="index-headline featured"><span>Written by</span></h5>
            <section class="author">
              <div class="author-image" style="background-image: url(/assets/images/author.jpg)">Blog Logo</div>
              <h4>Shams S</h4>
              <p class="bio">Data Scientist @ Practo</p>
              <hr>
              <p class="published">Published on <time datetime="2018-01-02 00:00">02 Jan 2018</time></p>
            </section>
          </div>
          <div class="isRight">
            <h5 class="index-headline featured"><span>Supported by</span></h5>
            <footer class="site-footer">
              <section class="poweredby">Proudly published with <a href="http://jekyllrb.com"> Jekyll</a></section>
              <a class="subscribe" href="/feed.xml"> <span class="tooltip"> <i class="fa fa-rss"></i> You should subscribe to my feed.</span></a>
              <div class="inner">
                <section class="copyright">All content copyright <a href="https://machinelearningmedium.com/">Machine Learning Medium</a> &copy; 2018<br>All rights reserved.</section>
              </div>
            </footer>
          </div>
        </div> -->
        <br>
        
        <div id="vc-feelback-main" data-access-token="334e9d2a5dc341469cda15d8c4bd935e" data-display-type="4"></div>
        
        
        <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE */
            var disqus_shortname = 'shams-sam'; /* required: replace example with your forum shortname */

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function() {
                var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        
      </article>
    </main>
    <!-- footer start -->
<div class="footer-container">

<footer class="site-footer">
  <a class="subscribe" href="/feed.xml"> <span class="tooltip"> <i class="fa fa-rss"></i> Subscribe!</span></a>
    <div class="inner">
         <section class="copyright">All content copyright <a href="/">Machine Learning Medium</a> &copy; 2018 &bull; All rights reserved.</section>
         <section class="poweredby">Made with <a href="http://jekyllrb.com"> Jekyll</a></section>
         <section class="poweredby">Inspired by <a href="https://medium.com/"> Medium</a> and <a href="https://github.com/dirkfabisch/mediator">Mediator</a></section>
    </div>
</footer>

<div class="bottom-closer">
  <div class="background-closer-image"  style="background-image: url(/assets/images/footer.jpg)">
    Image
  </div>
  <div class="inner">
    <h1 class="footer-title">Machine Learning Medium</h1>
    <h2 class="footer-description">A step away from the illusion of knowledge.</h2>
    <a href=/about/ class="btn">About Me</a>
  </div>
</div>

<!-- footer end -->
</div>

    <script src="https://code.jquery.com/jquery-1.11.1.min.js"></script>
<script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
<script type="text/javascript" src="/assets/js/readingTime.min.js"></script>
<script type="text/javascript" src="/assets/js/index.js"></script>
<script>
(function ($) {
  "use strict";
  $(document).ready(function(){

    var $window = $(window),
    $image = $('.post-image-image, .teaserimage-image');
    
      $window.on('scroll', function() {
        var top = $window.scrollTop();

        if (top < 0 || top > 1500) { return; }
        $image
          .css('transform', 'translate3d(0px, '+top/3+'px, 0px)')
          .css('opacity', 1-Math.max(top/700, 0));
      });
      $window.trigger('scroll');

      var height = $('.article-image').height();
      $('.post-content').css('padding-top', height + 'px');

      $('a[href*=#]:not([href=#])').click(function() {
        if (location.pathname.replace(/^\//,'') == this.pathname.replace(/^\//,'')
         && location.hostname == this.hostname) {
          var target = $(this.hash);
          target = target.length ? target : $('[name=' + this.hash.slice(1) +']');
          if (target.length) {
            $('html,body').animate({ scrollTop: target.offset().top }, 500);
            return false;
          }
        }
      });

  });
}(jQuery));
</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
<script src="/public/js/typed.js"></script>
<script>
  $(function(){
    $(".blog-description").typed({
      strings: ['A step away from the illusion of knowledge.'],
      typeSpeed: 50,
      backSpeed: 25,
      loop: true
    });
  });
</script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      },
      CommonHTML: {matchFontHeight: false},
      "HTML-CSS": {matchFontHeight: false},
      SVG: {matchFontHeight: false}
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>



<script>
   (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-108148924-1', 'auto');
ga('send', 'pageview');

</script>


<div id="fb-root"></div>

<script>
  (function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = 'https://connect.facebook.net/en_GB/sdk.js#xfbml=1&version=v2.10&appId=391866664565981';
    fjs.parentNode.insertBefore(js, fjs);
  }(document, 'script', 'facebook-jssdk'));
</script>


<script> 
(function() { 
  var v = document.createElement('script'); v.async = true; 
  v.src = "https://assets-prod.vicomi.com/vicomi.js?token=334e9d2a5dc341469cda15d8c4bd935e"; 
  var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(v, s); 
})(); 
</script>

  </body>
</html>
