<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <!-- (1) Optimize for mobile versions: http://goo.gl/EOpFl -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- (1) force latest IE rendering engine: bit.ly/1c8EiC9 -->
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  

  <title>Backpropagation Derivation | Machine Learning Medium</title>
  <meta name="description" content="The post delves into the mathematics of how backpropagation is defined. It has its roots in partial derivatives and is easily understandable" />

  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  
  
  <meta property="og:site_name" content="Machine Learning Medium" />
  <meta property="og:title" content="Backpropagation Derivation"/>
  
  <meta property="og:description" content="The post delves into the mathematics of how backpropagation is defined. It has its roots in partial derivatives and is easily understandable" />
  
  <meta property="og:image" content="https://machinelearningmedium.com/assets/images/backpropagation.jpg" />
  <meta property="og:url" content="https://machinelearningmedium.com/2018/03/20/backpropagation-derivation/" >
  <meta property="og:type" content="blog" />
  <meta property="article:published_time" content="2018-03-20T00:00:00+00:00">

  <link rel="canonical" href="https://machinelearningmedium.com/2018/03/20/backpropagation-derivation/"/>
  <link rel="shortcut icon" href="/public/fav.png" type="image/png"/>
  <link rel="stylesheet" href="//brick.a.ssl.fastly.net/Linux+Libertine:400,400i,700,700i/Open+Sans:400,400i,700,700i">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="stylesheet" type="text/css" media="screen" href="/css/main.css" />
  <link rel="stylesheet" type="text/css" media="print" href="/css/print.css" />
  <link rel="stylesheet" type="text/css" href="/css/custom.css" />
  <link rel="stylesheet" type="text/css" href="/public/css/share_bar.css" />
  <link rel="stylesheet" type="text/css" href="/public/css/syntax.css" />
  <link href="https://fonts.googleapis.com/css?family=Fira+Sans:400,600|Open+Sans:400,700" rel="stylesheet">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" >
  <link rel="shortcut icon" href="/public/fav.ico?v1">


  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

</head>

  <body itemscope itemtype="http://schema.org/Article">
    <div class="metabar metabar-header">
  <div class="metabar-inner">
    <div class="quote-div">
      <a class="icon-quote" href="/">
        <i class="fa fa-quote-left fa-pull-left fa-border" aria-hidden="true"></i>
      </a>
    </div>
  </div>
</div>

<div class="sectionbar sectionbar-header">
  <div class="sectionbar-inner">
    <div class="table">
      <div class="category-links table-cell">
        
          <a href=/>Home</a>
        
        
        <a href="/tag/machine-learning">Machine Learning</a>
        
        <a href="/tag/mathematics">Mathematics</a>
        
        <a href="/tag/papers">Papers</a>
        
        <span class="right-padding-22">|</span>
        <a href=/collections/ class="">Collections</a>
        <a href=/tags/ class="">Tags</a>
        
          <span class="right-padding-22">|</span>
          <a class="icon-search" href="/search/"><i class="fa fa-search"></i></a>
        
      </div>
      <div class="social-links table-cell">
        <!-- 
          
              <a class="icon-github-alt" href="https://github.com/shams-sam/shams-sam.github.io"  title="Gihub Project" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-github-alt fa-stack-1x"></i>
                </span>
              </a>
          
        
          
              <a class="icon-facebook" href="https://facebook.com/shams-sam"  title="Facebook" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-facebook fa-stack-1x"></i>
                </span>
              </a>
          
        
          
              <a class="icon-twitter" href="https://twitter.com/sshamsofficial"  title="Twitter" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-twitter fa-stack-1x"></i>
                </span>
              </a>
          
        
          
              <a class="icon-linkedin" href="https://linkedin.com/in/shams-sam"  title="LinkedIn" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-linkedin fa-stack-1x"></i>
                </span>
              </a>
          
        
          
              <a class="icon-envelope" href="mailto:azam1@purdue.edu"  title="E-mail" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-square-o fa-stack-2x"></i>
                  <i class="fa fa-envelope fa-stack-1x"></i>
                </span>
              </a>
          
         -->
        <div class="fb-like" data-href="https://www.facebook.com/machinelearningmedium/" data-layout="button" data-action="like" data-size="large" data-show-faces="false" data-share="false"></div>
        <a href="https://twitter.com/sshamsofficial" class="twitter-follow-button" data-size="large" data-show-screen-name="false" data-dnt="true" data-show-count="false"></a><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
      </div>
    </div>
  </div>
</div>
    <div class="author-strip">
      <div class="author-strip-inner">
        <div class="author-image" style="background-image: url(/assets/images/author.jpg)">Blog Logo</div>
        <div class="author-detail">
          <h4 class="author-name" itemprop="author" itemscope itemtype="http://schema.org/Person"><a href="/about/" style="color: #000000; text-decoration: none;">Shams S</a></h4>
          <h5 class="author-name"> Research Assistant @ Purdue University </h5>
          <time datetime="2018-03-20T00:00:00+00:00">Mar 20</time>
          <span class="middot">&#183;</span>
          <div class="post-reading">
            <span class="post-reading-time"></span> read
          </div>
        </div>
      </div>
    </div>
    
    <div class="postcover">
    <div class="postimage">
        <div class="postimage-image"  style="background-image: url(/assets/images/backpropagation.jpg) ">
        </div>
    </div>
    
    <figcaption>Image Source: http://4.bp.blogspot.com/-IzAlHMEgdxc/VSfHprh1ksI/AAAAAAAAAF0/z0RVFZxAZHw/s1600/IMG_20150410_132508~2~2~2.jpg</figcaption>
    
    </div>
    <main class="content post-content" role="main">
      <article class="post">
        <div class="noarticleimage">
          <div class="post-meta">
            <h1 class="post-title">Backpropagation Derivation</h1>
            <section class="share">
            <span id="share-bar">

    <span><i class="fa fa-share-alt"></i></span>

    <span class="share-buttons">
        <span>
        <a  href="https://www.facebook.com/sharer/sharer.php?u=https://machinelearningmedium.com/2018/03/20/backpropagation-derivation/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Facebook" >
            <i class="fa fa-facebook-square"></i>
        </a>
        </span>
        <span>
        <a  href="https://twitter.com/intent/tweet?text=Backpropagation Derivation&url=https://machinelearningmedium.com/2018/03/20/backpropagation-derivation/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Twitter" >
            <i class="fa fa-twitter-square"></i>
        </a>
        </span>
        <span>
        <a  href="https://plus.google.com/share?url=https://machinelearningmedium.com/2018/03/20/backpropagation-derivation/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Google+" >
            <i class="fa fa-google-plus-square"></i>
        </a>
        </span>
        <span>
        <a  href="http://pinterest.com/pin/create/button/?url=https://machinelearningmedium.com/2018/03/20/backpropagation-derivation/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Pinterest" >
            <i class="fa fa-pinterest-square"></i>
        </a>
        </span>
        <span>
        <a  href="http://www.tumblr.com/share/link?url=https://machinelearningmedium.com/2018/03/20/backpropagation-derivation/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Tumblr" >
            <i class="fa fa-tumblr-square"></i>
        </a>
        </span>
        <span>
        <a  href="http://www.reddit.com/submit?url=https://machinelearningmedium.com/2018/03/20/backpropagation-derivation/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Reddit" >
            <i class="fa fa-reddit-square"></i>
        </a>
        </span>
        <span>
        <a  href="https://www.linkedin.com/shareArticle?mini=true&url=https://machinelearningmedium.com/2018/03/20/backpropagation-derivation/&title=Backpropagation Derivation&summary=The post delves into the mathematics of how backpropagation is defined. It has its roots in partial derivatives and is easily understandable&source=Machine Learning Medium"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on LinkedIn" >
            <i class="fa fa-linkedin-square"></i>
        </a>
        </span>
        <span>
        <a  href="mailto:?subject=Backpropagation Derivation&amp;body=Check out this site https://machinelearningmedium.com/2018/03/20/backpropagation-derivation/"
            title="Share via Email" >
            <i class="fa fa-envelope-square"></i>
        </a>
        </span>
    </span>

</span>
          </section>
            <h2 class="post-description">The post delves into the mathematics of how backpropagation is defined. It has its roots in partial derivatives and is easily understandable</h2>
          </div>
        </div>
        <div class="horizontal-divider">&#183; &#183; &#183;</div>
        <section class="post-content">
          <a name="topofpage"></a>
          <h3 id="basics-of-machine-learning-series">Basics of Machine Learning Series</h3>

<blockquote>
  <p><a href="/collection/basics-of-machine-learning">Index</a></p>
</blockquote>

<div class="horizontal-divider">· · ·</div>

<h3 id="derivative-of-sigmoid">Derivative of Sigmoid</h3>

<p>The sigmoid function, represented by \(\sigma\) is defined as,</p>

<script type="math/tex; mode=display">\sigma(x)  = {1 \over 1 + e^{-x}} \tag{1} \label{1}</script>

<p>So, the derivative of \eqref{1}, denoted by \(\sigma’\) can be derived using the quotient rule of differentiation, i.e., if \(f\) and \(g\) are functions, then,</p>

<script type="math/tex; mode=display">\left({f \over g} \right)' = {f'g - g'f \over g^2} \tag{2} \label{2}</script>

<p>Since \(f\) is a constant (i.e. 1) in this case, \eqref{2} reduces to,</p>

<script type="math/tex; mode=display">\left({1 \over g} \right)' = {- g' \over g^2} \tag{3} \label{3}</script>

<p>Also, by the chain rule of differentiation, if \(h(x) = f(g(x))\), then,</p>

<script type="math/tex; mode=display">h'(x) = f'(g(x)) \cdot g'(x) \tag{4} \label{4}</script>

<p>Applying \eqref{3} and \eqref{4} to \eqref{1}, \(\sigma’(x)\) is given by,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\sigma'(x) &= -\frac{e^{-x}} {(1+e^{-x})^2} \cdot -1 \\
    &= \frac{e^{-x}} {(1+e^{-x})^2} \\
    &= {1 \over 1 + e^{-x}} \cdot \frac{1 + e^{-x} - 1} {1+e^{-x}} \\
    &= \sigma(x) \cdot \left(\frac{1 + e^{-x}} {1+e^{-x}} - \frac{1} {1+e^{-x}} \right) \\
\sigma'(x) &= \sigma(x) \cdot (1 - \sigma(x)) \tag{5} \label{5}
\end{align} %]]></script>

<h3 id="mathematics-of-backpropagation">Mathematics of Backpropagation</h3>

<p>(* all the derivations are based scalar calculus and not the matrix calculus for simplicity of calculations)</p>

<p>In most of the cases of algorithms like <strong>logistic regression, linear regression, there is no hidden layer</strong>, which basically zeroes down to the fact that there is no <strong>concept of error propagation in backward direction</strong> because there is a direct dependence of model cost function on the single layer of model parameters.</p>

<p>Backpropagation tries to do the similar exercise using the partial derivatives of model output with respect to the individual parameters. It so happens that there is a trend that can be observed when such derivatives are calculated and <strong>backpropagation tries to exploit the patterns</strong> and hence minimizes the overall computation by reusing the terms already calculated.</p>

<p>Consider a simple <strong>neural network with a single path</strong> (following the notation from <a href="/2017/10/03/neural-networks-cost-function-and-back-propagation/">Neural Networks: Cost Function and Backpropagation</a>) as shown below,</p>

<p><img src="/assets/2018-03-20-backpropagation-derivation/fig-1-single-path-neural-network.png?raw=true" alt="Fig-1. Single-Path Neural Network" /></p>

<p>where,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
a^{(1)} &= x^{(i)} \\ \\

z^{(2)} &= \theta^{(1)} a^{(1)} \\
a^{(2)} &= \sigma(z^{(2)}) \\ \\

z^{(3)} &= \theta^{(2)} a^{(2)} \\
a^{(3)} &= \sigma(z^{(3)}) \\ \\

z^{(4)} &= \theta^{(3)} a^{(3)} \\
a^{(4)} &= g(z^{(4)}) = h(x^{(i)}) = \hat{y}^{(i)} 
\end{align}
\tag{6} \label{6} %]]></script>

<p>where \(g\) is a linear function defined as \(g(x) = x\), and hence \(g’(x) = 1\). \(\sigma\) represents the sigmoid function.</p>

<p>For the simplicity of derivation, let the cost function, \(J\) be defined as,</p>

<script type="math/tex; mode=display">J = {1 \over 2} (\hat{y}^{(i)} - y^{(i)})^2 \tag{7} \label{7}</script>

<p>where,</p>

<script type="math/tex; mode=display">\delta^{(4)} = \hat{y}^{(i)} - y^{(i)} \tag{8} \label{8}</script>

<p>Now, in order to find the changes that should be made in the parameters (i.e. weights), partial derivatives of the cost function is calculated w.r.t. individual \(\theta’s\),</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\frac {\partial J} {\partial \theta^{(3)}} &= \frac {\partial} {\partial \theta^{(3)}} {1 \over 2} (\hat{y}^{(i)} - y^{(i)})^2 \\
    &= (\hat{y}^{(i)} - y^{(i)}) \frac {\partial} {\partial \theta^{(3)}} (g(\theta^{(3)} a^{(3)}) - y^{(i)}) \\
    &= (\hat{y}^{(i)} - y^{(i)}) \cdot a^{(3)} \\
    &= (\hat{y}^{(i)} - y^{(i)}) \cdot a^{(3)} \tag{9} \label{9} \\ \\

\frac {\partial J} {\partial \theta^{(2)}} &= \frac {\partial} {\partial \theta^{(2)}} {1 \over 2} (\hat{y}^{(i)} - y^{(i)})^2 \\
    &= (\hat{y}^{(i)} - y^{(i)}) \frac {\partial} {\partial \theta^{(2)}} (g(\theta^{(3)} \sigma(\theta^{(2)} a^{(2)})) - y^{(i)}) \\
    &= (\hat{y}^{(i)} - y^{(i)}) \cdot \theta^{(3)} \sigma'(z^{(3)}) \cdot a^{(2)} \tag{10} \label{10}\\ \\

\frac {\partial J} {\partial \theta^{(1)}} &= \frac {\partial} {\partial \theta^{(1)}} {1 \over 2} (\hat{y}^{(i)} - y^{(i)})^2 \\
    &= (\hat{y}^{(i)} - y^{(i)}) \frac {\partial} {\partial \theta^{(1)}} (g(\theta^{(3)} \sigma(\theta^{(2)} \sigma(\theta^{(1)} a^{(1)}))) - y^{(i)}) \\
    &= (\hat{y}^{(i)} - y^{(i)}) \cdot \theta^{(3)} \sigma'(z^{(3)}) \cdot \theta^{(2)} \sigma'(z^{(2)}) \cdot a^{(1)} \\
    &= (\hat{y}^{(i)} - y^{(i)}) \cdot \theta^{(3)} \sigma'(z^{(3)}) \cdot \theta^{(2)} \sigma'(z^{(2)}) \cdot x^{(i)} \tag{11} \label{11}
\end{align} %]]></script>

<p>One can see a pattern emerging among the partial derivatives of the cost function with respect to the individual parameters matrices. The expressions in \eqref{9}, \eqref{10} and \eqref{11} show that each term consists of <strong>the derivative of the network error</strong>, <strong>the weighted derivative of the node output with respect to the node input</strong> leading upto that node.</p>

<p>So, for this network the updates for the matrices are given by,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\Delta \theta^{(1)} &= - \eta [(\hat{y}^{(i)} - y^{(i)}) \cdot \theta^{(3)} \sigma'(z^{(3)}) \cdot \theta^{(2)} \sigma'(z^{(2)}) \cdot x^{(i)}] \\
\Delta \theta^{(2)} &= - \eta [(\hat{y}^{(i)} - y^{(i)}) \cdot \theta^{(3)} \sigma'(z^{(3)}) \cdot a^{(2)}] \\
\Delta \theta^{(3)} &= - \eta [(\hat{y}^{(i)} - y^{(i)}) \cdot a^{(3)}]
\end{align}
\tag{12} \label{12} %]]></script>

<blockquote>
  <p>Forward propagation is a recursive algorithm takes an input, weighs it along the edges and then applies the activation function in a node and repeats this process until the output node. Similarly, backpropagation is a recursive algorithm performing the inverse of the forward propagation, i.e. it takes the error signal from the output layer, weighs it along the edges and performs derivative of activation in an encountered node until it reaches the input. This brings in the concept of backward error propagation.</p>
</blockquote>

<h3 id="error-signal">Error Signal</h3>

<p>Following the concept of backward error propagation, error signal is defined as the accumulated error at each layer. The recursive error signal at a layer l is defined as,</p>

<script type="math/tex; mode=display">\delta^{(l)} = \frac {\partial J} {\partial z^{(l)}} \tag{13} \label{13}</script>

<p>Intuitively, it can be understood as the measure of how the network error changes with respect to the change in input to unit \(l\).</p>

<p>So, \(\delta^{(4)}\) in \eqref{8}, can be derived using \eqref{13},</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\delta^{(4)} &= \frac {\partial J} {\partial z^{(4)}} = \frac {\partial} {\partial z^{(4)}} {1 \over 2} (\hat{y}^{(i)} - y^{(i)})^2 \\\\
    &= (\hat{y}^{(i)} - y^{(i)}) \frac {\partial} {\partial z^{(4)}} (\hat{y}^{(i)} - y^{(i)}) \\
    &= (\hat{y}^{(i)} - y^{(i)}) \frac {\partial} {\partial z^{(4)}} (g(z^{(4)}) - y^{(i)}) \\ 
    &= (\hat{y}^{(i)} - y^{(i)}) \tag{14} \label{14}
\end{align} %]]></script>

<p>Similary the error signal at previous layers can be derived and it can be seen how the error signal of the forward layers get transmitted to the backward layers</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\delta^{(3)} &= \frac {\partial J} {\partial z^{(3)}} \\
    &= \frac {\partial} {\partial z^{(3)}} {1 \over 2} (\hat{y}^{(i)} - y^{(i)})^2 \\
    &= \delta^{(4)} \frac {\partial} {\partial z^{(3)}} (g(\theta^{(3)} \sigma(z^{(3)}))) \\
    &= \delta^{(4)} \theta^{(3)} \sigma'(z^{(3)}) \tag{15} \label{15} \\ \\ 

\delta^{(2)} &= \frac {\partial J} {\partial z^{(2)}} \\
    &= \frac {\partial} {\partial z^{(2)}} {1 \over 2} (\hat{y}^{(i)} - y^{(i)})^2 \\
    &= \delta^{(4)} \frac {\partial} {\partial z^{(2)}} (g(\theta^{(3)} \sigma(\theta^{(2)} \sigma(z^{(2)})))) \\
    &= \delta^{(4)} \theta^{(3)} \sigma'(z^{(3)}) \cdot \theta^{(2)} \sigma'(z^{(2)}) \\ 
    &= \delta^{(3)} \theta^{(2)} \sigma'(z^{(2)}) \tag{16} \label{16} \\
\end{align} %]]></script>

<p>Using \eqref{14}, \eqref{15} and \eqref{16}, \eqref{12} can be written as,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\Delta \theta^{(1)} &= - \eta \delta^{(2)} a^{(1)} \\
\Delta \theta^{(2)} &= - \eta \delta^{(3)} a^{(2)} \\
\Delta \theta^{(3)} &= - \eta \delta^{(4)} a^{(3)}
\end{align}
\tag{17} \label{17} %]]></script>

<p>which is nothing but the updates to individual parameter matrices based on partial derivatives of cost w.r.t. individual matrices.</p>

<h3 id="activation-function">Activation Function</h3>

<p>Generally, the choice of activation function at the output layer is dependent on the type of cost function. This is mainly to simplify the process of differentiation. For example, as shown in the example above, if the cost function is mean-squared error then choice of linear function as activation for the output layer often helps simplify calculations. Similarly, the cross-entropy loss works well with sigmoid or softmax activation functions. But this is not a hard and fast rule. One is free to use any activation function with any cost function, although the equations for partial derivatives might not look as nice.</p>

<p>Similarly, the choice of activation function in hidden layers are plenty. Although sigmoid functions are widely used, they suffer from vanishing gradient as the depth increases, hence other activations like ReLUs are recommended for deeper neural networks.</p>

<h2 id="references">REFERENCES:</h2>

<p><small><a href="http://briandolhansky.com/blog/2013/9/27/artificial-neural-networks-backpropagation-part-4" target="_blank">Artificial Neural Networks: Mathematics of Backpropagation (Part 4)</a></small><br />
<small><a href="https://stats.stackexchange.com/questions/218542/which-activation-function-for-output-layer" target="_blank">Which activation function for output layer?</a></small></p>

        </section>
        <footer class="post-footer">
          <div class="wrap">
            
              <div class="tile">
                <div class="text">
                <a href="/tag/andrew-ng" class='category-links'><h1>andrew-ng</h1></a>
                </div>
              </div>
            
              <div class="tile">
                <div class="text">
                <a href="/tag/machine-learning" class='category-links'><h1>machine-learning</h1></a>
                </div>
              </div>
            
              <div class="tile">
                <div class="text">
                <a href="/tag/mathematics" class='category-links'><h1>mathematics</h1></a>
                </div>
              </div>
            
          </div>
        </footer>
        <div class="horizontal-divider">· · ·</div>
        <!-- <div class="bottom-teaser cf">
          <div class="isLeft">
            <h5 class="index-headline featured"><span>Written by</span></h5>
            <section class="author">
              <div class="author-image" style="background-image: url(/assets/images/author.jpg)">Blog Logo</div>
              <h4>Shams S</h4>
              <p class="bio">Research Assistant @ Purdue University</p>
              <hr>
              <p class="published">Published on <time datetime="2018-03-20 00:00">20 Mar 2018</time></p>
            </section>
          </div>
          <div class="isRight">
            <h5 class="index-headline featured"><span>Supported by</span></h5>
            <footer class="site-footer">
              <section class="poweredby">Proudly published with <a href="http://jekyllrb.com"> Jekyll</a></section>
              <a class="subscribe" href="/feed.xml"> <span class="tooltip"> <i class="fa fa-rss"></i> You should subscribe to my feed.</span></a>
              <div class="inner">
                <section class="copyright">All content copyright <a href="https://machinelearningmedium.com/">Machine Learning Medium</a> &copy; 2020<br>All rights reserved.</section>
              </div>
            </footer>
          </div>
        </div> -->
        <br>
        
        <div id="vc-feelback-main" data-access-token="334e9d2a5dc341469cda15d8c4bd935e" data-display-type="4"></div>
        
        <nav class="page-navigation" role="navigation">
  
    <a href=/2018/03/08/program-in-pytorch/ class="arrow-button left-arrow-button"><span class="left-arrow"></span><span class="label left-label">Program in PyTorch</span></a>
  
  
    <a href=/2018/03/29/backpropagation-implementation-and-gradient-checking/ class="arrow-button right-arrow-button"><span class="label right-label">Backpropagation Implementation and Gradient Checking</span><span class="right-arrow"></span></a>
  
</nav>
        
        <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE */
            var disqus_shortname = 'shams-sam'; /* required: replace example with your forum shortname */

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function() {
                var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        
      </article>
    </main>
    <!-- footer start -->
<div class="footer-container">

<footer class="site-footer">
  <a class="subscribe" href="/feed.xml"> <span class="tooltip"> <i class="fa fa-rss"></i> Subscribe!</span></a>
    <div class="inner">
         <section class="copyright">All content copyright <a href="/">Machine Learning Medium</a> &copy; 2020 &bull; All rights reserved.</section>
         <section class="poweredby">Made with <a href="http://jekyllrb.com"> Jekyll</a></section>
         <section class="poweredby">Inspired by <a href="https://medium.com/"> Medium</a> and <a href="https://github.com/dirkfabisch/mediator">Mediator</a></section>
    </div>
</footer>

<div class="bottom-closer">
  <div class="background-closer-image"  style="background-image: url(/assets/images/footer.jpg)">
    Image
  </div>
  <div class="inner">
    <h1 class="footer-title">Machine Learning Medium</h1>
    <h2 class="footer-description">Recursing the Rabbit Hole</h2>
    <a href=/about/ class="btn">About Me</a>
  </div>
</div>

<!-- footer end -->
</div>

    <script src="https://code.jquery.com/jquery-1.11.1.min.js"></script>
<script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
<script type="text/javascript" src="/assets/js/readingTime.min.js"></script>
<script type="text/javascript" src="/assets/js/index.js"></script>
<script>
(function ($) {
  "use strict";
  $(document).ready(function(){

    var $window = $(window),
    $image = $('.post-image-image, .teaserimage-image');
    
      $window.on('scroll', function() {
        var top = $window.scrollTop();

        if (top < 0 || top > 1500) { return; }
        $image
          .css('transform', 'translate3d(0px, '+top/3+'px, 0px)')
          .css('opacity', 1-Math.max(top/700, 0));
      });
      $window.trigger('scroll');

      var height = $('.article-image').height();
      $('.post-content').css('padding-top', height + 'px');

      $('a[href*=#]:not([href=#])').click(function() {
        if (location.pathname.replace(/^\//,'') == this.pathname.replace(/^\//,'')
         && location.hostname == this.hostname) {
          var target = $(this.hash);
          target = target.length ? target : $('[name=' + this.hash.slice(1) +']');
          if (target.length) {
            $('html,body').animate({ scrollTop: target.offset().top }, 500);
            return false;
          }
        }
      });

  });
}(jQuery));
</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
<script src="/public/js/typed.js"></script>
<script>
  $(function(){
    $(".blog-description").typed({
      strings: ['Recursing the Rabbit Hole'],
      typeSpeed: 50,
      backSpeed: 25,
      loop: true
    });
  });
</script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      },
      CommonHTML: {matchFontHeight: false},
      "HTML-CSS": {matchFontHeight: false},
      SVG: {matchFontHeight: false}
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>



<script>
   (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-108148924-1', 'auto');
ga('send', 'pageview');

</script>


<div id="fb-root"></div>

<script>
  (function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = 'https://connect.facebook.net/en_GB/sdk.js#xfbml=1&version=v2.10&appId=391866664565981';
    fjs.parentNode.insertBefore(js, fjs);
  }(document, 'script', 'facebook-jssdk'));
</script>


<script> 
(function() { 
  var v = document.createElement('script'); v.async = true; 
  v.src = "https://assets-prod.vicomi.com/vicomi.js?token=334e9d2a5dc341469cda15d8c4bd935e"; 
  var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(v, s); 
})(); 
</script>

  </body>
</html>
